commit dea880d9d8939eb3f1c9825d7870468613409e26
Author: Dmitry Lenev <dlenev@mysql.com>
Date:   2010-01-21

    Patch that changes metadata locking subsystem to use mutex per lock and
    condition variable per context instead of one mutex and one conditional
    variable for the whole subsystem.
    
    This should increase concurrency in this subsystem.
    
    It also opens the way for further changes which are necessary to solve
    such bugs as bug #46272 "MySQL 5.4.4, new MDL: unnecessary deadlock"
    and bug #37346 "innodb does not detect deadlock between update and alter
    table".
    
    Two other notable changes done by this patch:
    
    - MDL subsystem no longer implicitly acquires global intention exclusive
      metadata lock when per-object metadata lock is acquired. Now this has
      to be done by explicit calls outside of MDL subsystem.
    - Instead of using separate MDL_context for opening system tables/tables
      for purposes of I_S we now create MDL savepoint in the main context
      before opening tables and rollback to this savepoint after closing
      them. This means that it is now possible to get ER_LOCK_DEADLOCK error
      even not inside a transaction. This might happen in unlikely case when
      one runs DDL on one of system tables while also running DDL on some
      other tables. Cases when this ER_LOCK_DEADLOCK error is not justified
      will be addressed by advanced deadlock detector for MDL subsystem which
      we plan to implement.
 
diff --git a/sql/events.cc b/sql/events.cc
index d4efcdb..ef5bf80 100644
--- a/sql/events.cc
+++ b/sql/events.cc
@@ -772,3 +772,3 @@ Events::show_create_event(THD *thd, LEX_STRING dbname, LEX_STRING name)
 {
-  Open_tables_state open_tables_backup;
+  Open_tables_backup open_tables_backup;
   Event_timed et;
@@ -828,3 +828,3 @@ Events::fill_schema_events(THD *thd, TABLE_LIST *tables, COND * /* cond */)
   int ret;
-  Open_tables_state open_tables_backup;
+  Open_tables_backup open_tables_backup;
   DBUG_ENTER("Events::fill_schema_events");
diff --git a/sql/ha_ndbcluster.cc b/sql/ha_ndbcluster.cc
index b357461..220e5c4 100644
--- a/sql/ha_ndbcluster.cc
+++ b/sql/ha_ndbcluster.cc
@@ -7287,10 +7287,6 @@ int ndbcluster_find_files(handlerton *hton, THD *thd,
     a deadlock, and therefore is disallowed by assertions of the metadata
-    locking subsystem. In order to temporarily make the code work, we must
-    reset and backup the open tables state, thus hide the existing locks
-    from MDL asserts. But in the essence this is violation of metadata
+    locking subsystem. This is violation of metadata
     locking protocol which has to be closed ASAP.
+    XXX: the scenario described above is not covered with any test.
   */
-  Open_tables_state open_tables_state_backup;
-  thd->reset_n_backup_open_tables_state(&open_tables_state_backup);
-
   if (!global_read_lock)
@@ -7318,4 +7314,2 @@ int ndbcluster_find_files(handlerton *hton, THD *thd,
 
-  thd->restore_backup_open_tables_state(&open_tables_state_backup);
-
   /* Lock mutex before creating .FRM files. */
diff --git a/sql/lock.cc b/sql/lock.cc
index 6cdf2e4..9d794b0 100644
--- a/sql/lock.cc
+++ b/sql/lock.cc
@@ -951,4 +951,7 @@ bool lock_table_names(THD *thd, TABLE_LIST *table_list)
   MDL_request_list mdl_requests;
+  MDL_request global_request;
   TABLE_LIST *lock_table;
 
+  global_request.init(MDL_key::GLOBAL, "", "", MDL_INTENTION_EXCLUSIVE);
+
   for (lock_table= table_list; lock_table; lock_table= lock_table->next_local)
@@ -960,4 +963,11 @@ bool lock_table_names(THD *thd, TABLE_LIST *table_list)
   }
+
+  if (thd->mdl_context.acquire_global_intention_exclusive_lock(&global_request))
+    return 1;
+
   if (thd->mdl_context.acquire_exclusive_locks(&mdl_requests))
+  {
+    thd->mdl_context.release_lock(global_request.ticket);
     return 1;
+  }
   return 0;
@@ -1011,2 +1021,3 @@ bool lock_routine_name(THD *thd, bool is_function,
                                          MDL_key::PROCEDURE);
+  MDL_request global_request;
   MDL_request mdl_request;
@@ -1023,6 +1034,13 @@ bool lock_routine_name(THD *thd, bool is_function,
 
+  global_request.init(MDL_key::GLOBAL, "", "", MDL_INTENTION_EXCLUSIVE);
   mdl_request.init(mdl_type, db, name, MDL_EXCLUSIVE);
 
+  if (thd->mdl_context.acquire_global_intention_exclusive_lock(&global_request))
+    return TRUE;
+
   if (thd->mdl_context.acquire_exclusive_lock(&mdl_request))
+  {
+    thd->mdl_context.release_lock(global_request.ticket);
     return TRUE;
+  }
 
diff --git a/sql/log.cc b/sql/log.cc
index a74fc94..e1f98ff 100644
--- a/sql/log.cc
+++ b/sql/log.cc
@@ -412,3 +412,3 @@ bool Log_to_csv_event_handler::
   Silence_log_table_errors error_handler;
-  Open_tables_state open_tables_backup;
+  Open_tables_backup open_tables_backup;
   ulonglong save_thd_options;
@@ -574,3 +574,3 @@ bool Log_to_csv_event_handler::
   Silence_log_table_errors error_handler;
-  Open_tables_state open_tables_backup;
+  Open_tables_backup open_tables_backup;
   CHARSET_INFO *client_cs= thd->variables.character_set_client;
@@ -729,3 +729,3 @@ int Log_to_csv_event_handler::
   int result;
-  Open_tables_state open_tables_backup;
+  Open_tables_backup open_tables_backup;
 
diff --git a/sql/mdl.cc b/sql/mdl.cc
index af7f310..dce917a 100644
--- a/sql/mdl.cc
+++ b/sql/mdl.cc
@@ -23,2 +23,27 @@ static bool mdl_initialized= 0;
 
+
+/**
+  A collection of all MDL locks. A singleton,
+  there is only one instance of the map in the server.
+  Maps MDL_key to MDL_lock instances.
+*/
+
+class MDL_map
+{
+public:
+  void init();
+  void destroy();
+  MDL_lock *find(const MDL_key *key);
+  MDL_lock *find_or_insert(const MDL_key *key);
+  void remove(MDL_lock *lock);
+private:
+  bool move_from_hash_to_lock_mutex(MDL_lock *lock);
+private:
+  /** All acquired locks in the server. */
+  HASH m_locks;
+  /* Protects access to m_locks hash. */
+  pthread_mutex_t m_mutex;
+};
+
+
 /**
@@ -28,2 +53,6 @@ static bool mdl_initialized= 0;
   Can be seen as an MDL subsystem's version of TABLE_SHARE.
+
+  This is an abstract class which lacks information about
+  compatibility rules for lock types. They should be specified
+  in its descendants.
 */
@@ -41,8 +70,3 @@ public:
 
-  /** The type of lock (shared or exclusive). */
-  enum
-  {
-    MDL_LOCK_SHARED,
-    MDL_LOCK_EXCLUSIVE,
-  } type;
+public:
   /** The key of the object (data) being protected. */
@@ -51,3 +75,6 @@ public:
   Ticket_list granted;
+  /** Tickets for contexts waiting to acquire a shared lock. */
+  Ticket_list waiting_shared;
   /**
+    Tickets for contexts waiting to acquire an exclusive lock.
     There can be several upgraders and active exclusive
@@ -57,5 +84,7 @@ public:
   */
-  Ticket_list waiting;
+  Ticket_list waiting_exclusive;
   void   *cached_object;
   mdl_cached_object_release_hook cached_object_release_hook;
+  /** Mutex protecting this lock context. */
+  pthread_mutex_t m_mutex;
 
@@ -63,46 +92,79 @@ public:
   {
-    return (granted.is_empty() && waiting.is_empty());
+    return (granted.is_empty() && waiting_shared.is_empty() &&
+            waiting_exclusive.is_empty());
   }
 
-  bool can_grant_lock(const MDL_context *requestor_ctx,
-                      enum_mdl_type type, bool is_upgrade);
+  bool has_pending_exclusive_lock()
+  {
+    bool has_locks;
+    pthread_mutex_lock(&m_mutex);
+    has_locks= ! waiting_exclusive.is_empty();
+    pthread_mutex_unlock(&m_mutex);
+    return has_locks;
+  }
+  virtual bool can_grant_lock(const MDL_context *requestor_ctx,
+                              enum_mdl_type type, bool is_upgrade)= 0;
+  virtual void wake_up_waiters()= 0;
 
   inline static MDL_lock *create(const MDL_key *key);
-  inline static void destroy(MDL_lock *lock);
-private:
+
   MDL_lock(const MDL_key *key_arg)
-  : type(MDL_LOCK_SHARED),
-    key(key_arg),
+  : key(key_arg),
     cached_object(NULL),
-    cached_object_release_hook(NULL)
+    cached_object_release_hook(NULL),
+    m_ref_usage(0),
+    m_ref_release(0),
+    m_is_destroyed(FALSE)
   {
+    pthread_mutex_init(&m_mutex, NULL);
   }
-};
 
+  virtual ~MDL_lock()
+  {
+    pthread_mutex_destroy(&m_mutex);
+  }
+  inline static void destroy(MDL_lock *lock);
+public:
+  /**
+    These three members are used to make it possible to separate
+    the mdl_locks.m_mutex mutex and MDL_lock::m_mutex in
+    MDL_map::find_or_insert() for increased scalability.
+    The 'm_is_destroyed' member is only set by destroyers that
+    have both the mdl_locks.m_mutex and MDL_lock::m_mutex, thus
+    holding any of the mutexes is sufficient to read it.
+    The 'm_ref_usage; is incremented under protection by
+    mdl_locks.m_mutex, but when 'm_is_destroyed' is set to TRUE, this
+    member is moved to be protected by the MDL_lock::m_mutex.
+    This means that the MDL_map::find_or_insert() which only
+    holds the MDL_lock::m_mutex can compare it to 'm_ref_release'
+    without acquiring mdl_locks.m_mutex again and if equal it can also
+    destroy the lock object safely.
+    The 'm_ref_release' is incremented under protection by
+    MDL_lock::m_mutex.
+    Note since we are only interested in equality of these two
+    counters we don't have to worry about overflows as long as
+    their size is big enough to hold maximum number of concurrent
+    threads on the system.
+  */
+  uint m_ref_usage;
+  uint m_ref_release;
+  bool m_is_destroyed;
+};
 
-static pthread_mutex_t LOCK_mdl;
-static pthread_cond_t  COND_mdl;
-static HASH mdl_locks;
 
 /**
-  An implementation of the global metadata lock. The only
-  locking modes which are supported at the moment are SHARED and
-  INTENTION EXCLUSIVE. Note, that SHARED global metadata lock
-  is acquired automatically when one tries to acquire an EXCLUSIVE
-  or UPGRADABLE SHARED metadata lock on an individual object.
+  An implementation of the global metadata lock. The only locking modes
+  which are supported at the moment are SHARED and INTENTION EXCLUSIVE.
 */
 
-class MDL_global_lock
+class MDL_global_lock : public MDL_lock
 {
 public:
-  uint waiting_shared;
-  uint active_shared;
-  uint active_intention_exclusive;
+  MDL_global_lock(const MDL_key *key_arg)
+    : MDL_lock(key_arg)
+  { }
 
-  bool is_empty() const
-  {
-    return (waiting_shared == 0 && active_shared == 0 &&
-            active_intention_exclusive == 0);
-  }
-  bool is_lock_type_compatible(enum_mdl_type type, bool is_upgrade) const;
+  virtual bool can_grant_lock(const MDL_context *requestor_ctx,
+                              enum_mdl_type type, bool is_upgrade);
+  virtual void wake_up_waiters();
 };
@@ -110,4 +172,21 @@ public:
 
-static MDL_global_lock global_lock;
+/**
+  An implementation of a per-object lock. Supports SHARED, SHARED_UPGRADABLE,
+  SHARED HIGH PRIORITY and EXCLUSIVE locks.
+*/
+
+class MDL_object_lock : public MDL_lock
+{
+public:
+  MDL_object_lock(const MDL_key *key_arg)
+    : MDL_lock(key_arg)
+  { }
+
+  virtual bool can_grant_lock(const MDL_context *requestor_ctx,
+                              enum_mdl_type type, bool is_upgrade);
+  virtual void wake_up_waiters();
+};
+
 
+static MDL_map mdl_locks;
 
@@ -149,8 +228,3 @@ void mdl_init()
   mdl_initialized= TRUE;
-  pthread_mutex_init(&LOCK_mdl, NULL);
-  pthread_cond_init(&COND_mdl, NULL);
-  my_hash_init(&mdl_locks, &my_charset_bin, 16 /* FIXME */, 0, 0,
-               mdl_locks_key, 0, 0);
-  /* The global lock is zero-initialized by the loader. */
-  DBUG_ASSERT(global_lock.is_empty());
+  mdl_locks.init();
 }
@@ -170,7 +244,3 @@ void mdl_destroy()
     mdl_initialized= FALSE;
-    DBUG_ASSERT(!mdl_locks.records);
-    DBUG_ASSERT(global_lock.is_empty());
-    pthread_mutex_destroy(&LOCK_mdl);
-    pthread_cond_destroy(&COND_mdl);
-    my_hash_free(&mdl_locks);
+    mdl_locks.destroy();
   }
@@ -179,22 +249,190 @@ void mdl_destroy()
 
+/** Initialize the global hash containing all MDL locks. */
+
+void MDL_map::init()
+{
+  pthread_mutex_init(&m_mutex, NULL);
+  my_hash_init(&m_locks, &my_charset_bin, 16 /* FIXME */, 0, 0,
+               mdl_locks_key, 0, 0);
+}
+
+
 /**
-  Initialize a metadata locking context.
+  Destroy the global hash containing all MDL locks.
+  @pre It must be empty.
+*/
 
-  This is to be called when a new server connection is created.
+void MDL_map::destroy()
+{
+  DBUG_ASSERT(!m_locks.records);
+  pthread_mutex_destroy(&m_mutex);
+  my_hash_free(&m_locks);
+}
+
+
+/**
+  Find MDL_lock object corresponding to the key, create it
+  if it does not exist.
+
+  @retval non-NULL - Success. MDL_lock instance for the key with
+                     locked MDL_lock::m_mutex.
+  @retval NULL     - Failure (OOM).
+*/
+
+MDL_lock* MDL_map::find_or_insert(const MDL_key *mdl_key)
+{
+  MDL_lock *lock;
+
+retry:
+  pthread_mutex_lock(&m_mutex);
+  if (!(lock= (MDL_lock*) my_hash_search(&m_locks,
+                                         mdl_key->ptr(),
+                                         mdl_key->length())))
+  {
+    lock= MDL_lock::create(mdl_key);
+    if (!lock || my_hash_insert(&m_locks, (uchar*)lock))
+    {
+      pthread_mutex_unlock(&m_mutex);
+      MDL_lock::destroy(lock);
+      return NULL;
+    }
+  }
+
+  if (move_from_hash_to_lock_mutex(lock))
+    goto retry;
+
+  return lock;
+}
+
+
+/**
+  Find MDL_lock object corresponding to the key.
+
+  @retval non-NULL - MDL_lock instance for the key with locked
+                     MDL_lock::m_mutex.
+  @retval NULL     - There was no MDL_lock for the key.
+*/
+
+MDL_lock* MDL_map::find(const MDL_key *mdl_key)
+{
+  MDL_lock *lock;
+
+retry:
+  pthread_mutex_lock(&m_mutex);
+  if (!(lock= (MDL_lock*) my_hash_search(&m_locks,
+                                         mdl_key->ptr(),
+                                         mdl_key->length())))
+  {
+    pthread_mutex_unlock(&m_mutex);
+    return NULL;
+  }
+
+  if (move_from_hash_to_lock_mutex(lock))
+    goto retry;
+
+  return lock;
+}
+
+
+/**
+  Release mdl_locks.m_mutex mutex and lock MDL_lock::m_mutex for lock
+  object from the hash. Handle situation when object was released
+  while the held no mutex.
+
+  @retval FALSE - Success.
+  @retval TRUE  - Object was released while we held no mutex, caller
+                  should re-try looking up MDL_lock object in the hash.
 */
 
-void MDL_context::init(THD *thd_arg)
+bool MDL_map::move_from_hash_to_lock_mutex(MDL_lock *lock)
 {
-  m_has_global_shared_lock= FALSE;
-  m_thd= thd_arg;
-  m_lt_or_ha_sentinel= NULL;
+  DBUG_ASSERT(! lock->m_is_destroyed);
+  safe_mutex_assert_owner(&m_mutex);
+
   /*
-    FIXME: In reset_n_backup_open_tables_state,
-    we abuse "init" as a reset, i.e. call it on an already
-    constructed non-empty object. This is why we can't
-    rely here on the default constructors of I_P_List
-    to empty the list.
+    We increment m_ref_usage which is a reference counter protected by
+    mdl_locks.m_mutex under the condition it is present in the hash and
+    m_is_destroyed is FALSE.
   */
-  m_tickets.empty();
-  m_is_waiting_in_mdl= FALSE;
+  lock->m_ref_usage++;
+  pthread_mutex_unlock(&m_mutex);
+
+  pthread_mutex_lock(&lock->m_mutex);
+  lock->m_ref_release++;
+  if (unlikely(lock->m_is_destroyed))
+  {
+    /*
+      Object was released while we held no mutex, we need to
+      release it if no others hold references to it, while our own
+      reference count ensured that the object as such haven't got
+      its memory released yet. We can also safely compare
+      m_ref_usage and m_ref_release since the object is no longer
+      present in the hash so no one will be able to find it and
+      increment m_ref_usage anymore.
+    */
+    uint ref_usage= lock->m_ref_usage;
+    uint ref_release= lock->m_ref_release;
+    pthread_mutex_unlock(&lock->m_mutex);
+    if (ref_usage == ref_release)
+      MDL_lock::destroy(lock);
+    return TRUE;
+  }
+  return FALSE;
+}
+
+
+/**
+  Destroy MDL_lock object or delegate this responsibility to
+  whatever thread that holds the last outstanding reference to
+  it.
+*/
+
+void MDL_map::remove(MDL_lock *lock)
+{
+  uint ref_usage, ref_release;
+
+  safe_mutex_assert_owner(&lock->m_mutex);
+
+  if (lock->cached_object)
+    (*lock->cached_object_release_hook)(lock->cached_object);
+
+  /*
+    Destroy the MDL_lock object, but ensure that anyone that is
+    holding a reference to the object is not remaining, if so he
+    has the responsibility to release it.
+
+    Setting of m_is_destroyed to TRUE while holding _both_
+    mdl_locks.m_mutex and MDL_lock::m_mutex mutexes transfers the
+    protection of m_ref_usage from mdl_locks.m_mutex to
+    MDL_lock::m_mutex while removal of object from the hash makes
+    it read-only.  Therefore whoever acquires MDL_lock::m_mutex next
+    will see most up to date version of m_ref_usage.
+
+    This means that when m_is_destroyed is TRUE and we hold the
+    MDL_lock::m_mutex we can safely read the m_ref_usage
+    member.
+  */
+  pthread_mutex_lock(&m_mutex);
+  my_hash_delete(&m_locks, (uchar*) lock);
+  lock->m_is_destroyed= TRUE;
+  ref_usage= lock->m_ref_usage;
+  ref_release= lock->m_ref_release;
+  pthread_mutex_unlock(&lock->m_mutex);
+  pthread_mutex_unlock(&m_mutex);
+  if (ref_usage == ref_release)
+    MDL_lock::destroy(lock);
+}
+
+
+/**
+  Initialize a metadata locking context.
+
+  This is to be called when a new server connection is created.
+*/
+
+MDL_context::MDL_context()
+  :m_lt_or_ha_sentinel(NULL),
+  m_thd(NULL)
+{
+  pthread_cond_init(&m_ctx_wakeup_cond, NULL);
 }
@@ -217,3 +455,3 @@ void MDL_context::destroy()
   DBUG_ASSERT(m_tickets.is_empty());
-  DBUG_ASSERT(! m_has_global_shared_lock);
+  pthread_cond_destroy(&m_ctx_wakeup_cond);
 }
@@ -307,2 +545,4 @@ MDL_request::create(MDL_key::enum_mdl_namespace mdl_namespace, const char *db,
 
+  @note Also chooses an MDL_lock descendant appropriate for object namespace.
+
   @todo This naive implementation should be replaced with one that saves
@@ -313,3 +553,9 @@ inline MDL_lock *MDL_lock::create(const MDL_key *mdl_key)
 {
-  return new MDL_lock(mdl_key);
+  switch (mdl_key->mdl_namespace())
+  {
+    case MDL_key::GLOBAL:
+      return new MDL_global_lock(mdl_key);
+    default:
+      return new MDL_object_lock(mdl_key);
+  }
 }
@@ -323,2 +569,4 @@ void MDL_lock::destroy(MDL_lock *lock)
 
+
+
 /**
@@ -356,3 +604,4 @@ void MDL_ticket::destroy(MDL_ticket *ticket)
 
-#define MDL_ENTER_COND(A, B) mdl_enter_cond(A, B, __func__, __FILE__, __LINE__)
+#define MDL_ENTER_COND(A, B, C, D) \
+        mdl_enter_cond(A, B, C, D, __func__, __FILE__, __LINE__)
 
@@ -360,2 +609,4 @@ static inline const char *mdl_enter_cond(THD *thd,
                                          st_my_thread_var *mysys_var,
+                                         pthread_cond_t *cond,
+                                         pthread_mutex_t *mutex,
                                          const char *calling_func,
@@ -364,6 +615,6 @@ static inline const char *mdl_enter_cond(THD *thd,
 {
-  safe_mutex_assert_owner(&LOCK_mdl);
+  safe_mutex_assert_owner(mutex);
 
-  mysys_var->current_mutex= &LOCK_mdl;
-  mysys_var->current_cond= &COND_mdl;
+  mysys_var->current_mutex= mutex;
+  mysys_var->current_cond= cond;
 
@@ -375,3 +626,4 @@ static inline const char *mdl_enter_cond(THD *thd,
 
-#define MDL_EXIT_COND(A, B, C) mdl_exit_cond(A, B, C, __func__, __FILE__, __LINE__)
+#define MDL_EXIT_COND(A, B, C, D) \
+        mdl_exit_cond(A, B, C, D, __func__, __FILE__, __LINE__)
 
@@ -379,2 +631,3 @@ static inline void mdl_exit_cond(THD *thd,
                                  st_my_thread_var *mysys_var,
+                                 pthread_mutex_t *mutex,
                                  const char* old_msg,
@@ -384,5 +637,5 @@ static inline void mdl_exit_cond(THD *thd,
 {
-  DBUG_ASSERT(&LOCK_mdl == mysys_var->current_mutex);
+  DBUG_ASSERT(mutex == mysys_var->current_mutex);
 
-  pthread_mutex_unlock(&LOCK_mdl);
+  pthread_mutex_unlock(mutex);
   pthread_mutex_lock(&mysys_var->mutex);
@@ -400,11 +653,10 @@ static inline void mdl_exit_cond(THD *thd,
 /**
-  Check if request for the lock on particular object can be satisfied given
-  current state of the global metadata lock.
+  Check if request for the global metadata lock can be satisfied given
+  its current state,
 
-  @note In other words, we're trying to check that the individual lock
-        request, implying a form of lock on the global metadata, is
-        compatible with the current state of the global metadata lock.
-
-  @param mdl_request  Request for lock on an individual object, implying a
-                      certain kind of global metadata lock.
+  @param  requestor_ctx  The context that identifies the owner of the request.
+  @param  type_arg       The requested type of global lock. Usually derived
+                         from the type of lock on individual object to be
+                         requested. See table below.
+  @param  is_upgrade     TRUE if we are performing lock upgrade (not unused).
 
@@ -428,3 +680,3 @@ static inline void mdl_exit_cond(THD *thd,
         "-" -- means that request can't be satisfied and should wait
-        "0" -- means impossible situation which will trigger assert
+        "0" -- means impossible situation.
 
@@ -438,17 +690,14 @@ static inline void mdl_exit_cond(THD *thd,
 bool
-MDL_global_lock::is_lock_type_compatible(enum_mdl_type type,
-                                         bool is_upgrade) const
+MDL_global_lock::can_grant_lock(const MDL_context *requestor_ctx,
+                                enum_mdl_type type_arg,
+                                bool is_upgrade)
 {
-  switch (type)
+  switch (type_arg)
   {
   case MDL_SHARED:
-  case MDL_SHARED_HIGH_PRIO:
-    return TRUE;
-    break;
-  case MDL_SHARED_UPGRADABLE:
-    if (active_shared || waiting_shared)
+    if (! granted.is_empty() && granted.front()->m_type == MDL_INTENTION_EXCLUSIVE)
     {
       /*
-        We are going to obtain intention exclusive global lock and
-        there is active or pending shared global lock. Have to wait.
+        We are going to obtain global shared lock and there is active
+        intention exclusive lock. Have to wait.
       */
@@ -456,30 +705,16 @@ MDL_global_lock::is_lock_type_compatible(enum_mdl_type type,
     }
-    else
-      return TRUE;
+    return TRUE;
     break;
-  case MDL_EXCLUSIVE:
-    if (is_upgrade)
+  case MDL_INTENTION_EXCLUSIVE:
+    if ((! granted.is_empty() && granted.front()->m_type == MDL_SHARED) ||
+        ! waiting_shared.is_empty())
     {
       /*
-        We are upgrading MDL_SHARED to MDL_EXCLUSIVE.
-
-        There should be no conflicting global locks since for each upgradable
-        shared lock we obtain intention exclusive global lock first.
+        We are going to obtain intention exclusive global lock and
+        there is active or pending shared global lock. Have to wait.
       */
-      DBUG_ASSERT(active_shared == 0 && active_intention_exclusive);
-      return TRUE;
+      return FALSE;
     }
     else
-    {
-      if (active_shared || waiting_shared)
-      {
-        /*
-          We are going to obtain intention exclusive global lock and
-          there is active or pending shared global lock.
-        */
-        return FALSE;
-      }
-      else
-        return TRUE;
-    }
+      return TRUE;
     break;
@@ -487,2 +722,3 @@ MDL_global_lock::is_lock_type_compatible(enum_mdl_type type,
     DBUG_ASSERT(0);
+    break;
   }
@@ -493,3 +729,55 @@ MDL_global_lock::is_lock_type_compatible(enum_mdl_type type,
 /**
-  Check if request for the lock can be satisfied given current state of lock.
+  Wake up contexts which are waiting to acquire the global
+  metadata lock and which may succeed now, when we released it, or
+  removed a blocking request for it from the waiters list.
+  The latter can happen when the context trying to acquire the
+  global shared lock is killed.
+*/
+
+void MDL_global_lock::wake_up_waiters()
+{
+  /*
+    If there are no active locks or they are of INTENTION
+    EXCLUSIVE type and there are no pending requests for global
+    SHARED lock, wake up contexts waiting for an INTENTION
+    EXCLUSIVE lock.
+    This happens when we release the global SHARED lock or abort
+    or remove a pending request for it, i.e. abort the
+    context waiting for it.
+  */
+  if ((granted.is_empty() ||
+       granted.front()->m_type == MDL_INTENTION_EXCLUSIVE) &&
+      waiting_shared.is_empty() && ! waiting_exclusive.is_empty())
+  {
+    MDL_lock::Ticket_iterator it(waiting_exclusive);
+    MDL_ticket *awake_ticket;
+    while ((awake_ticket= it++))
+      awake_ticket->get_ctx()->awake();
+  }
+
+  /*
+    If there are no active locks, wake up contexts waiting for
+    the global shared lock (happens when an INTENTION EXCLUSIVE
+    lock is released).
+
+    We don't wake up contexts waiting for the global shared lock
+    if there is an active global shared lock since such situation
+    is transient and in it contexts marked as waiting for global
+    shared lock must be already woken up and simply have not
+    managed to update lock object yet.
+  */
+  if (granted.is_empty() &&
+      ! waiting_shared.is_empty())
+  {
+    MDL_lock::Ticket_iterator it(waiting_shared);
+    MDL_ticket *awake_ticket;
+    while ((awake_ticket= it++))
+      awake_ticket->get_ctx()->awake();
+  }
+}
+
+
+/**
+  Check if request for the per-object lock can be satisfied given current
+  state of the lock.
 
@@ -525,4 +813,5 @@ MDL_global_lock::is_lock_type_compatible(enum_mdl_type type,
 bool
-MDL_lock::can_grant_lock(const MDL_context *requestor_ctx, enum_mdl_type type_arg,
-                         bool is_upgrade)
+MDL_object_lock::can_grant_lock(const MDL_context *requestor_ctx,
+                                enum_mdl_type type_arg,
+                                bool is_upgrade)
 {
@@ -534,6 +823,6 @@ MDL_lock::can_grant_lock(const MDL_context *requestor_ctx, enum_mdl_type type_ar
   case MDL_SHARED_HIGH_PRIO:
-    if (type == MDL_lock::MDL_LOCK_SHARED)
+    if (granted.is_empty() || granted.front()->is_shared())
     {
       /* Pending exclusive locks have higher priority over shared locks. */
-      if (waiting.is_empty() || type_arg == MDL_SHARED_HIGH_PRIO)
+      if (waiting_exclusive.is_empty() || type_arg == MDL_SHARED_HIGH_PRIO)
         can_grant= TRUE;
@@ -561,3 +850,3 @@ MDL_lock::can_grant_lock(const MDL_context *requestor_ctx, enum_mdl_type type_ar
       */
-      DBUG_ASSERT(type == MDL_lock::MDL_LOCK_SHARED);
+      DBUG_ASSERT(granted.front()->is_shared());
 
@@ -578,5 +867,9 @@ MDL_lock::can_grant_lock(const MDL_context *requestor_ctx, enum_mdl_type type_ar
     }
-    else if (type == MDL_lock::MDL_LOCK_SHARED)
+    else if (granted.is_empty())
     {
-      can_grant= granted.is_empty();
+      /*
+        We are trying to acquire fresh MDL_EXCLUSIVE and there are no active
+        shared or exclusive locks.
+      */
+      can_grant= TRUE;
     }
@@ -591,2 +884,40 @@ MDL_lock::can_grant_lock(const MDL_context *requestor_ctx, enum_mdl_type type_ar
 /**
+  Wake up contexts which are waiting to acquire lock on individual object
+  and which may succeed now, when we released some lock on it or removed
+  some pending request from its waiters list (the latter can happen, for
+  example, when context trying to acquire exclusive lock is killed).
+*/
+
+void MDL_object_lock::wake_up_waiters()
+{
+  /*
+    There are no active locks or they are of shared type.
+    We have to wake up contexts waiting for shared lock even if there is
+    a pending exclusive lock as some them might be trying to acquire high
+    priority shared lock.
+  */
+  if ((granted.is_empty() || granted.front()->is_shared()) &&
+      ! waiting_shared.is_empty())
+  {
+    MDL_lock::Ticket_iterator it(waiting_shared);
+    MDL_ticket *waiting_ticket;
+    while ((waiting_ticket= it++))
+      waiting_ticket->get_ctx()->awake();
+  }
+
+  /*
+    There are no active locks (shared or exclusive).
+    Wake up contexts waiting to acquire exclusive locks.
+  */
+  if (granted.is_empty() && ! waiting_exclusive.is_empty())
+  {
+    MDL_lock::Ticket_iterator it(waiting_exclusive);
+    MDL_ticket *waiting_ticket;
+    while ((waiting_ticket= it++))
+      waiting_ticket->get_ctx()->awake();
+  }
+}
+
+
+/**
   Check whether the context already holds a compatible lock ticket
@@ -628,11 +959,180 @@ MDL_context::find_ticket(MDL_request *mdl_request,
 /**
-  Try to acquire one shared lock.
+  Try to acquire global intention exclusive lock.
 
-  Unlike exclusive locks, shared locks are acquired one by
-  one. This is interface is chosen to simplify introduction of
-  the new locking API to the system. MDL_context::try_acquire_shared_lock()
-  is currently used from open_table(), and there we have only one
-  table to work with.
+  @param[in/out]  mdl_request  Lock request object for lock to be acquired
 
-  In future we may consider allocating multiple shared locks at once.
+  @retval  FALSE   Success. The lock may have not been acquired.
+                   One needs to check value of 'MDL_request::ticket'
+                   to find out what has happened.
+  @retval  TRUE    Error.
+*/
+
+bool
+MDL_context::
+try_acquire_global_intention_exclusive_lock(MDL_request *mdl_request)
+{
+  DBUG_ASSERT(mdl_request->key.mdl_namespace() == MDL_key::GLOBAL &&
+              mdl_request->type == MDL_INTENTION_EXCLUSIVE);
+
+  if (is_global_lock_owner(MDL_SHARED))
+  {
+    my_error(ER_CANT_UPDATE_WITH_READLOCK, MYF(0));
+    return TRUE;
+  }
+
+  return try_acquire_lock_impl(mdl_request);
+}
+
+
+/**
+  Acquire one lock with waiting for conflicting locks to go away if needed.
+
+  @note This is an internal method which should not be used outside of MDL
+        subsystem as in most cases simply waiting for conflicting locks to
+        go away will lead to deadlock.
+
+  @param mdl_request [in/out] Lock request object for lock to be acquired
+
+  @retval  FALSE   Success. MDL_request::ticket points to the ticket
+                   for the lock.
+  @retval  TRUE    Failure (Out of resources or waiting is aborted),
+*/
+
+bool
+MDL_context::acquire_lock_impl(MDL_request *mdl_request)
+{
+  bool not_used;
+  MDL_ticket *ticket;
+  MDL_key *key= &mdl_request->key;
+  MDL_lock *lock;
+  const char *old_msg;
+  st_my_thread_var *mysys_var= my_thread_var;
+
+  DBUG_ASSERT(mdl_request->ticket == NULL);
+  safe_mutex_assert_not_owner(&LOCK_open);
+
+  /*
+    Grant lock without waiting if this context already owns this type of lock
+    on this object.
+
+    The fact that we don't wait in such situation allows to avoid deadlocks
+    in cases when pending request for global shared lock pops up after the
+    moment when thread has acquired its first intention exclusive lock but
+    before it has requested the second instance of such lock.
+  */
+  if ((mdl_request->ticket= find_ticket(mdl_request, &not_used)))
+    return FALSE;
+
+  if (! (ticket= MDL_ticket::create(this, mdl_request->type)))
+    return TRUE;
+
+  /* The below call also implicitly locks MDL_lock::m_mutex. */
+  if (! (lock= mdl_locks.find_or_insert(key)))
+  {
+    MDL_ticket::destroy(ticket);
+    return TRUE;
+  }
+
+  old_msg= MDL_ENTER_COND(m_thd, mysys_var, &m_ctx_wakeup_cond,
+                          &lock->m_mutex);
+
+  if (! lock->can_grant_lock(this, mdl_request->type, FALSE))
+  {
+    if (mdl_request->is_shared())
+      lock->waiting_shared.push_front(ticket);
+    else
+      lock->waiting_exclusive.push_front(ticket);
+
+    do
+    {
+      pthread_cond_wait(&m_ctx_wakeup_cond, &lock->m_mutex);
+    }
+    while (! lock->can_grant_lock(this, mdl_request->type, FALSE) &&
+           ! mysys_var->abort);
+
+    if (mysys_var->abort)
+    {
+      /*
+        We have to do MDL_EXIT_COND here and then re-acquire the lock
+        as there is a chance that we will destroy MDL_lock object and
+        won't be able to call MDL_EXIT_COND after it.
+      */
+      MDL_EXIT_COND(m_thd, mysys_var, &lock->m_mutex, old_msg);
+
+      pthread_mutex_lock(&lock->m_mutex);
+      /* Get rid of pending ticket. */
+      if (mdl_request->is_shared())
+        lock->waiting_shared.remove(ticket);
+      else
+        lock->waiting_exclusive.remove(ticket);
+      if (lock->is_empty())
+        mdl_locks.remove(lock);
+      else
+      {
+        lock->wake_up_waiters();
+        pthread_mutex_unlock(&lock->m_mutex);
+      }
+      MDL_ticket::destroy(ticket);
+      return TRUE;
+    }
+
+    if (mdl_request->is_shared())
+      lock->waiting_shared.remove(ticket);
+    else
+      lock->waiting_exclusive.remove(ticket);
+  }
+
+  lock->granted.push_front(ticket);
+  MDL_EXIT_COND(m_thd, mysys_var, &lock->m_mutex, old_msg);
+
+  ticket->m_state= MDL_ACQUIRED;
+  ticket->m_lock= lock;
+
+  m_tickets.push_front(ticket);
+
+  mdl_request->ticket= ticket;
+
+  return FALSE;
+}
+
+
+/**
+  Acquire global intention exclusive lock.
+
+  @param[in]  mdl_request  Lock request object for lock to be acquired
+
+  @retval  FALSE   Success. The lock has been acquired.
+  @retval  TRUE    Error.
+*/
+
+bool
+MDL_context::acquire_global_intention_exclusive_lock(MDL_request *mdl_request)
+{
+  DBUG_ASSERT(mdl_request->key.mdl_namespace() == MDL_key::GLOBAL &&
+              mdl_request->type == MDL_INTENTION_EXCLUSIVE);
+
+  if (is_global_lock_owner(MDL_SHARED))
+  {
+    my_error(ER_CANT_UPDATE_WITH_READLOCK, MYF(0));
+    return TRUE;
+  }
+
+  /*
+    If this is a non-recursive attempt to acquire global intention
+    exclusive lock we might have to wait until active global shared
+    lock or pending requests will go away. Since we won't hold any
+    resources (except associated with open HANDLERs) while doing it
+    deadlocks are not possible,
+  */
+  DBUG_ASSERT(is_global_lock_owner(MDL_INTENTION_EXCLUSIVE) ||
+              ! has_locks() ||
+              (m_lt_or_ha_sentinel &&
+               m_tickets.front() == m_lt_or_ha_sentinel));
+
+  return acquire_lock_impl(mdl_request);
+}
+
+
+/**
+  Try to acquire one lock.
 
@@ -642,5 +1142,3 @@ MDL_context::find_ticket(MDL_request *mdl_request,
                    Check the ticket, if it's NULL, a conflicting lock
-                   exists and another attempt should be made after releasing
-                   all current locks and waiting for conflicting lock go
-                   away (using MDL_context::wait_for_locks()).
+                   exists.
   @retval  TRUE    Out of resources, an error has been reported.
@@ -649,3 +1147,3 @@ MDL_context::find_ticket(MDL_request *mdl_request,
 bool
-MDL_context::try_acquire_shared_lock(MDL_request *mdl_request)
+MDL_context::try_acquire_lock_impl(MDL_request *mdl_request)
 {
@@ -656,3 +1154,3 @@ MDL_context::try_acquire_shared_lock(MDL_request *mdl_request)
 
-  DBUG_ASSERT(mdl_request->is_shared() && mdl_request->ticket == NULL);
+  DBUG_ASSERT(mdl_request->ticket == NULL);
 
@@ -662,9 +1160,2 @@ MDL_context::try_acquire_shared_lock(MDL_request *mdl_request)
 
-  if (m_has_global_shared_lock &&
-      mdl_request->type == MDL_SHARED_UPGRADABLE)
-  {
-    my_error(ER_CANT_UPDATE_WITH_READLOCK, MYF(0));
-    return TRUE;
-  }
-
   /*
@@ -676,4 +1167,3 @@ MDL_context::try_acquire_shared_lock(MDL_request *mdl_request)
     DBUG_ASSERT(ticket->m_state == MDL_ACQUIRED);
-    /* Only shared locks can be recursive. */
-    DBUG_ASSERT(ticket->is_shared());
+    DBUG_ASSERT(ticket->m_type == mdl_request->type);
     /*
@@ -705,28 +1195,10 @@ MDL_context::try_acquire_shared_lock(MDL_request *mdl_request)
 
-  pthread_mutex_lock(&LOCK_mdl);
-
-  if (!global_lock.is_lock_type_compatible(mdl_request->type, FALSE))
-  {
-    pthread_mutex_unlock(&LOCK_mdl);
-    return FALSE;
-  }
-
   if (!(ticket= MDL_ticket::create(this, mdl_request->type)))
-  {
-    pthread_mutex_unlock(&LOCK_mdl);
     return TRUE;
-  }
 
-  if (!(lock= (MDL_lock*) my_hash_search(&mdl_locks,
-                                         key->ptr(), key->length())))
+  /* The below call also implicitly locks MDL_lock::m_mutex. */
+  if (!(lock= mdl_locks.find_or_insert(key)))
   {
-    /* Default lock type is MDL_lock::MDL_LOCK_SHARED */
-    lock= MDL_lock::create(key);
-    if (!lock || my_hash_insert(&mdl_locks, (uchar*)lock))
-    {
-      MDL_lock::destroy(lock);
-      MDL_ticket::destroy(ticket);
-      pthread_mutex_unlock(&LOCK_mdl);
-      return TRUE;
-    }
+    MDL_ticket::destroy(ticket);
+    return TRUE;
   }
@@ -735,9 +1207,11 @@ MDL_context::try_acquire_shared_lock(MDL_request *mdl_request)
   {
-    mdl_request->ticket= ticket;
     lock->granted.push_front(ticket);
-    m_tickets.push_front(ticket);
+    pthread_mutex_unlock(&lock->m_mutex);
+
     ticket->m_state= MDL_ACQUIRED;
     ticket->m_lock= lock;
-    if (mdl_request->type == MDL_SHARED_UPGRADABLE)
-      global_lock.active_intention_exclusive++;
+
+    m_tickets.push_front(ticket);
+
+    mdl_request->ticket= ticket;
   }
@@ -747,5 +1221,5 @@ MDL_context::try_acquire_shared_lock(MDL_request *mdl_request)
     DBUG_ASSERT(! lock->is_empty());
+    pthread_mutex_unlock(&lock->m_mutex);
     MDL_ticket::destroy(ticket);
   }
-  pthread_mutex_unlock(&LOCK_mdl);
 
@@ -756,2 +1230,34 @@ MDL_context::try_acquire_shared_lock(MDL_request *mdl_request)
 /**
+  Try to acquire one shared lock.
+
+  Unlike exclusive locks, shared locks are acquired one by
+  one. This is interface is chosen to simplify introduction of
+  the new locking API to the system. MDL_context::try_acquire_shared_lock()
+  is currently used from open_table(), and there we have only one
+  table to work with.
+
+  In future we may consider allocating multiple shared locks at once.
+
+  @param mdl_request [in/out] Lock request object for lock to be acquired
+
+  @retval  FALSE   Success. The lock may have not been acquired.
+                   Check the ticket, if it's NULL, a conflicting lock
+                   exists and another attempt should be made after releasing
+                   all current locks and waiting for conflicting lock go
+                   away (using MDL_context::wait_for_locks()).
+  @retval  TRUE    Out of resources, an error has been reported.
+*/
+
+bool
+MDL_context::try_acquire_shared_lock(MDL_request *mdl_request)
+{
+  DBUG_ASSERT(mdl_request->is_shared());
+  DBUG_ASSERT(mdl_request->type != MDL_SHARED_UPGRADABLE ||
+              is_global_lock_owner(MDL_INTENTION_EXCLUSIVE));
+
+  return try_acquire_lock_impl(mdl_request);
+}
+
+
+/**
   Create a copy of a granted ticket. 
@@ -784,7 +1290,200 @@ MDL_context::clone_ticket(MDL_request *mdl_request)
 
-  pthread_mutex_lock(&LOCK_mdl);
+  pthread_mutex_lock(&ticket->m_lock->m_mutex);
   ticket->m_lock->granted.push_front(ticket);
-  if (mdl_request->type == MDL_SHARED_UPGRADABLE)
-    global_lock.active_intention_exclusive++;
-  pthread_mutex_unlock(&LOCK_mdl);
+  pthread_mutex_unlock(&ticket->m_lock->m_mutex);
+
+  m_tickets.push_front(ticket);
+
+  return FALSE;
+}
+
+/**
+  Notify a thread holding a shared metadata lock which
+  conflicts with a pending exclusive lock.
+
+  @param thd               Current thread context
+  @param conflicting_ticket  Conflicting metadata lock
+*/
+
+void notify_shared_lock(THD *thd, MDL_ticket *conflicting_ticket)
+{
+  if (conflicting_ticket->is_shared())
+  {
+    THD *conflicting_thd= conflicting_ticket->get_ctx()->get_thd();
+    DBUG_ASSERT(thd != conflicting_thd); /* Self-deadlock */
+
+    /*
+      If the thread that holds the conflicting lock is waiting in MDL
+      subsystem it has to be woken up by calling MDL_context::awake().
+    */
+    conflicting_ticket->get_ctx()->awake();
+    /*
+      If it is waiting on table-level lock or some other non-MDL resource
+      we delegate its waking up to code outside of MDL.
+    */
+    mysql_notify_thread_having_shared_lock(thd, conflicting_thd);
+  }
+}
+
+
+/**
+  Auxiliary method for acquiring an exclusive lock.
+
+  @param mdl_request  Request for the lock to be acqured.
+
+  @note Should not be used outside of MDL subsystem. Instead one should
+        call acquire_exclusive_lock() or acquire_exclusive_locks() methods
+        which ensure that conditions for deadlock-free lock acquisition are
+        fulfilled.
+
+  @retval FALSE  Success
+  @retval TRUE   Failure
+*/
+
+bool MDL_context::acquire_exclusive_lock_impl(MDL_request *mdl_request)
+{
+  MDL_lock *lock;
+  const char *old_msg;
+  MDL_ticket *ticket;
+  bool not_used;
+  st_my_thread_var *mysys_var= my_thread_var;
+  MDL_key *key= &mdl_request->key;
+
+  DBUG_ASSERT(mdl_request->type == MDL_EXCLUSIVE &&
+              mdl_request->ticket == NULL);
+
+  safe_mutex_assert_not_owner(&LOCK_open);
+
+  /* Don't take chances in production. */
+  mdl_request->ticket= NULL;
+
+  /*
+    Check whether the context already holds an exclusive lock on the object,
+    and if so, grant the request.
+  */
+  if ((ticket= find_ticket(mdl_request, &not_used)))
+  {
+    DBUG_ASSERT(ticket->m_state == MDL_ACQUIRED);
+    DBUG_ASSERT(ticket->m_type == MDL_EXCLUSIVE);
+    mdl_request->ticket= ticket;
+    return FALSE;
+  }
+
+  DBUG_ASSERT(is_global_lock_owner(MDL_INTENTION_EXCLUSIVE));
+
+  /* Early allocation: ticket will be needed in any case. */
+  if (!(ticket= MDL_ticket::create(this, mdl_request->type)))
+    return TRUE;
+
+  /* The below call also implicitly locks MDL_lock::m_mutex. */
+  if (!(lock= mdl_locks.find_or_insert(key)))
+  {
+    MDL_ticket::destroy(ticket);
+    return TRUE;
+  }
+
+  lock->waiting_exclusive.push_front(ticket);
+
+  old_msg= MDL_ENTER_COND(m_thd, mysys_var, &m_ctx_wakeup_cond,
+                          &lock->m_mutex);
+
+  while (!lock->can_grant_lock(this, mdl_request->type, FALSE))
+  {
+    if (m_lt_or_ha_sentinel)
+    {
+      /*
+        We're about to start waiting. Don't do it if we have
+        HANDLER locks (we can't have any other locks here).
+        Waiting with locks may lead to a deadlock.
+
+        We have to do MDL_EXIT_COND here and then re-acquire the
+        lock as there is a chance that we will destroy MDL_lock
+        object and won't be able to call MDL_EXIT_COND after it.
+      */
+      MDL_EXIT_COND(m_thd, mysys_var, &lock->m_mutex, old_msg);
+
+      pthread_mutex_lock(&lock->m_mutex);
+      /* Get rid of pending ticket. */
+      lock->waiting_exclusive.remove(ticket);
+      if (lock->is_empty())
+        mdl_locks.remove(lock);
+      else
+      {
+        /*
+          There can be some contexts waiting to acquire shared
+          lock which now might be able to do it. Wake them up!
+        */
+        lock->wake_up_waiters();
+        pthread_mutex_unlock(&lock->m_mutex);
+      }
+      MDL_ticket::destroy(ticket);
+      my_error(ER_LOCK_DEADLOCK, MYF(0));
+      return TRUE;
+    }
+
+    MDL_ticket *conflicting_ticket;
+    MDL_lock::Ticket_iterator it(lock->granted);
+
+    while ((conflicting_ticket= it++))
+      notify_shared_lock(m_thd, conflicting_ticket);
+
+    /* There is a shared or exclusive lock on the object. */
+    DEBUG_SYNC(m_thd, "mdl_acquire_exclusive_locks_wait");
+
+    /*
+      Another thread might have obtained a shared MDL lock on some table
+      but has not yet opened it and/or tried to obtain data lock on it.
+      Also invocation of acquire_exclusive_lock() method and consequently
+      first call to notify_shared_lock() might have happened right after
+      thread holding shared metadata lock in wait_for_locks() method
+      checked that there are no pending conflicting locks but before
+      it has started waiting.
+      In both these cases we need to sleep until these threads will start
+      waiting and try to abort them once again.
+
+      QQ: What is the optimal value for this sleep?
+    */
+    struct timespec abstime;
+    set_timespec(abstime, 1);
+    pthread_cond_timedwait(&m_ctx_wakeup_cond, &lock->m_mutex, &abstime);
+
+    if (mysys_var->abort)
+    {
+      /*
+        We have to do MDL_EXIT_COND here and then re-acquire the lock
+        as there is a chance that we will destroy MDL_lock object and
+        won't be able to call MDL_EXIT_COND after it.
+      */
+      MDL_EXIT_COND(m_thd, mysys_var, &lock->m_mutex, old_msg);
+
+      pthread_mutex_lock(&lock->m_mutex);
+      /* Get rid of pending ticket. */
+      lock->waiting_exclusive.remove(ticket);
+      if (lock->is_empty())
+        mdl_locks.remove(lock);
+      else
+      {
+        /*
+          There can be some contexts waiting to acquire shared
+          lock which now might be able to do it. Wake them up!
+        */
+        lock->wake_up_waiters();
+        pthread_mutex_unlock(&lock->m_mutex);
+      }
+      MDL_ticket::destroy(ticket);
+      return TRUE;
+    }
+  }
+
+  lock->waiting_exclusive.remove(ticket);
+  lock->granted.push_front(ticket);
+
+  if (lock->cached_object)
+    (*lock->cached_object_release_hook)(lock->cached_object);
+  lock->cached_object= NULL;
+
+  MDL_EXIT_COND(m_thd, mysys_var, &lock->m_mutex, old_msg);
+
+  ticket->m_state= MDL_ACQUIRED;
+  ticket->m_lock= lock;
 
@@ -792,2 +1491,4 @@ MDL_context::clone_ticket(MDL_request *mdl_request)
 
+  mdl_request->ticket= ticket;
+
   return FALSE;
@@ -795,37 +1496,22 @@ MDL_context::clone_ticket(MDL_request *mdl_request)
 
+
 /**
-  Notify a thread holding a shared metadata lock which
-  conflicts with a pending exclusive lock.
+  Acquire an exclusive lock.
 
-  @param thd               Current thread context
-  @param conflicting_ticket  Conflicting metadata lock
+  @param mdl_request  Request for the lock to be acqured.
 
-  @retval TRUE   A thread was woken up
-  @retval FALSE  Lock is not a shared one or no thread was woken up
+  @note Assumes that one already owns global intention exclusive lock.
+
+  @retval FALSE  Success
+  @retval TRUE   Failure
 */
 
-bool notify_shared_lock(THD *thd, MDL_ticket *conflicting_ticket)
+bool MDL_context::acquire_exclusive_lock(MDL_request *mdl_request)
 {
-  bool woke= FALSE;
-  if (conflicting_ticket->is_shared())
-  {
-    THD *conflicting_thd= conflicting_ticket->get_ctx()->get_thd();
-    DBUG_ASSERT(thd != conflicting_thd); /* Self-deadlock */
+  /* Exclusive locks must always be acquired first, all at once. */
+  DBUG_ASSERT(! m_tickets.is_empty() &&
+              m_tickets.front()->m_lock->key.mdl_namespace() == MDL_key::GLOBAL &&
+              ++Ticket_list::Iterator(m_tickets) == m_lt_or_ha_sentinel);
 
-    /*
-      If the thread that holds the conflicting lock is waiting
-      on an MDL lock, wake it up by broadcasting on COND_mdl.
-      Otherwise it must be waiting on a table-level lock
-      or some other non-MDL resource, so delegate its waking up
-      to an external call.
-    */
-    if (conflicting_ticket->get_ctx()->is_waiting_in_mdl())
-    {
-      pthread_cond_broadcast(&COND_mdl);
-      woke= TRUE;
-    }
-    else
-      woke= mysql_notify_thread_having_shared_lock(thd, conflicting_thd);
-  }
-  return woke;
+  return acquire_exclusive_lock_impl(mdl_request);
 }
@@ -833,12 +1519,7 @@ bool notify_shared_lock(THD *thd, MDL_ticket *conflicting_ticket)
 
-/**
-  Acquire a single exclusive lock. A convenience
-  wrapper around the method acquiring a list of locks.
-*/
-
-bool MDL_context::acquire_exclusive_lock(MDL_request *mdl_request)
+extern "C" int mdl_request_ptr_cmp(const void* ptr1, const void* ptr2)
 {
-  MDL_request_list mdl_requests;
-  mdl_requests.push_front(mdl_request);
-  return acquire_exclusive_locks(&mdl_requests);
+  MDL_request *req1= *(MDL_request**)ptr1;
+  MDL_request *req2= *(MDL_request**)ptr2;
+  return req1->key.cmp(&req2->key);
 }
@@ -847,4 +1528,3 @@ bool MDL_context::acquire_exclusive_lock(MDL_request *mdl_request)
 /**
-  Acquire exclusive locks. The context must contain the list of
-  locks to be acquired. There must be no granted locks in the
+  Acquire exclusive locks. There must be no granted locks in the
   context.
@@ -854,4 +1534,8 @@ bool MDL_context::acquire_exclusive_lock(MDL_request *mdl_request)
 
-  @note The MDL context may not have non-exclusive lock requests
-        or acquired locks.
+  @param  mdl_requests  List of requests for locks to be acquired.
+
+  @note The list of requests should not contain non-exclusive lock requests.
+        There should not be any acquired locks in the context.
+
+  @note Assumes that one already owns global intention exclusive lock.
 
@@ -863,136 +1547,34 @@ bool MDL_context::acquire_exclusive_locks(MDL_request_list *mdl_requests)
 {
-  MDL_lock *lock;
-  bool signalled= FALSE;
-  const char *old_msg;
-  MDL_request *mdl_request;
-  MDL_ticket *ticket;
-  st_my_thread_var *mysys_var= my_thread_var;
   MDL_request_list::Iterator it(*mdl_requests);
+  MDL_request **sort_buf;
+  uint i;
 
-  safe_mutex_assert_not_owner(&LOCK_open);
-  /* Exclusive locks must always be acquired first, all at once. */
-  DBUG_ASSERT(! has_locks() ||
-              (m_lt_or_ha_sentinel &&
-               m_tickets.front() == m_lt_or_ha_sentinel));
-
-  if (m_has_global_shared_lock)
-  {
-    my_error(ER_CANT_UPDATE_WITH_READLOCK, MYF(0));
-    return TRUE;
-  }
-
-  pthread_mutex_lock(&LOCK_mdl);
-
-  old_msg= MDL_ENTER_COND(m_thd, mysys_var);
-
-  while ((mdl_request= it++))
-  {
-    MDL_key *key= &mdl_request->key;
-    DBUG_ASSERT(mdl_request->type == MDL_EXCLUSIVE &&
-                mdl_request->ticket == NULL);
+  /*
+    Exclusive locks must always be acquired first, all at once.
+  */
+  DBUG_ASSERT(! m_tickets.is_empty() &&
+              m_tickets.front()->m_lock->key.mdl_namespace() == MDL_key::GLOBAL &&
+              ++Ticket_list::Iterator(m_tickets) == m_lt_or_ha_sentinel);
 
-    /* Don't take chances in production. */
-    mdl_request->ticket= NULL;
+  if (mdl_requests->is_empty())
+    return FALSE;
 
-    /* Early allocation: ticket is used as a shortcut to the lock. */
-    if (!(ticket= MDL_ticket::create(this, mdl_request->type)))
-      goto err;
+  /* Sort requests according to MDL_key. */
+  if (! (sort_buf= (MDL_request **)my_malloc(mdl_requests->elements() *
+                                             sizeof(MDL_request *),
+                                             MYF(MY_WME))))
+    return TRUE;
 
-    if (!(lock= (MDL_lock*) my_hash_search(&mdl_locks,
-                                           key->ptr(), key->length())))
-    {
-      lock= MDL_lock::create(key);
-      if (!lock || my_hash_insert(&mdl_locks, (uchar*)lock))
-      {
-        MDL_ticket::destroy(ticket);
-        MDL_lock::destroy(lock);
-        goto err;
-      }
-    }
+  for (i= 0; i < mdl_requests->elements(); i++)
+    sort_buf[i]= it++;
 
-    mdl_request->ticket= ticket;
-    lock->waiting.push_front(ticket);
-    ticket->m_lock= lock;
-  }
+  my_qsort(sort_buf, mdl_requests->elements(), sizeof(MDL_request*),
+           mdl_request_ptr_cmp);
 
-  while (1)
+  for (i= 0; i < mdl_requests->elements(); i++)
   {
-    it.rewind();
-    while ((mdl_request= it++))
-    {
-      lock= mdl_request->ticket->m_lock;
-
-      if (!global_lock.is_lock_type_compatible(mdl_request->type, FALSE))
-      {
-        /*
-          Someone owns or wants to acquire the global shared lock so
-          we have to wait until he goes away.
-        */
-        signalled= TRUE;
-        break;
-      }
-      else if (!lock->can_grant_lock(this, mdl_request->type, FALSE))
-      {
-        MDL_ticket *conflicting_ticket;
-        MDL_lock::Ticket_iterator it(lock->granted);
-
-        signalled= (lock->type == MDL_lock::MDL_LOCK_EXCLUSIVE);
-
-        while ((conflicting_ticket= it++))
-          signalled|= notify_shared_lock(m_thd, conflicting_ticket);
-
-        break;
-      }
-    }
-    if (!mdl_request)
-      break;
-
-    if (m_lt_or_ha_sentinel)
-    {
-      /*
-        We're about to start waiting. Don't do it if we have
-        HANDLER locks (we can't have any other locks here).
-        Waiting with locks may lead to a deadlock.
-      */
-      my_error(ER_LOCK_DEADLOCK, MYF(0));
-      goto err;
-    }
-
-    /* There is a shared or exclusive lock on the object. */
-    DEBUG_SYNC(m_thd, "mdl_acquire_exclusive_locks_wait");
-
-    if (signalled)
-      pthread_cond_wait(&COND_mdl, &LOCK_mdl);
-    else
-    {
-      /*
-        Another thread obtained a shared MDL lock on some table but
-        has not yet opened it and/or tried to obtain data lock on
-        it. In this case we need to wait until this happens and try
-        to abort this thread once again.
-      */
-      struct timespec abstime;
-      set_timespec(abstime, 1);
-      pthread_cond_timedwait(&COND_mdl, &LOCK_mdl, &abstime);
-    }
-    if (mysys_var->abort)
+    if (acquire_exclusive_lock_impl(sort_buf[i]))
       goto err;
   }
-  it.rewind();
-  while ((mdl_request= it++))
-  {
-    global_lock.active_intention_exclusive++;
-    ticket= mdl_request->ticket;
-    lock= ticket->m_lock;
-    lock->type= MDL_lock::MDL_LOCK_EXCLUSIVE;
-    lock->waiting.remove(ticket);
-    lock->granted.push_front(ticket);
-    m_tickets.push_front(ticket);
-    ticket->m_state= MDL_ACQUIRED;
-    if (lock->cached_object)
-      (*lock->cached_object_release_hook)(lock->cached_object);
-    lock->cached_object= NULL;
-  }
-  /* As a side-effect MDL_EXIT_COND() unlocks LOCK_mdl. */
-  MDL_EXIT_COND(m_thd, mysys_var, old_msg);
+  my_free(sort_buf, MYF(0));
   return FALSE;
@@ -1000,22 +1582,10 @@ bool MDL_context::acquire_exclusive_locks(MDL_request_list *mdl_requests)
 err:
-  /* Remove our pending tickets from the locks. */
-  it.rewind();
-  while ((mdl_request= it++) && mdl_request->ticket)
+  /* Release locks we have managed to acquire so far. */
+  for (i= 0; i < mdl_requests->elements() && sort_buf[i]->ticket; i++)
   {
-    ticket= mdl_request->ticket;
-    DBUG_ASSERT(ticket->m_state == MDL_PENDING);
-    lock= ticket->m_lock;
-    lock->waiting.remove(ticket);
-    MDL_ticket::destroy(ticket);
+    release_lock(sort_buf[i]->ticket);
     /* Reset lock request back to its initial state. */
-    mdl_request->ticket= NULL;
-    if (lock->is_empty())
-    {
-      my_hash_delete(&mdl_locks, (uchar *)lock);
-      MDL_lock::destroy(lock);
-    }
+    sort_buf[i]->ticket= NULL;
   }
-  /* May be some pending requests for shared locks can be satisfied now. */
-  pthread_cond_broadcast(&COND_mdl);
-  MDL_EXIT_COND(m_thd, mysys_var, old_msg);
+  my_free(sort_buf, MYF(0));
   return TRUE;
@@ -1064,2 +1634,8 @@ MDL_ticket::upgrade_shared_lock_to_exclusive()
   /*
+    Since we should have already acquired an intention exclusive
+    global lock this call is only enforcing asserts.
+  */
+  DBUG_ASSERT(m_ctx->is_global_lock_owner(MDL_INTENTION_EXCLUSIVE));
+
+  /*
     Create an auxiliary ticket to represent a pending exclusive
@@ -1074,14 +1650,8 @@ MDL_ticket::upgrade_shared_lock_to_exclusive()
 
-  pthread_mutex_lock(&LOCK_mdl);
-
-  pending_ticket->m_lock= m_lock;
-  m_lock->waiting.push_front(pending_ticket);
+  pthread_mutex_lock(&m_lock->m_mutex);
 
-  old_msg= MDL_ENTER_COND(thd, mysys_var);
+  m_lock->waiting_exclusive.push_front(pending_ticket);
 
-  /*
-    Since we should have already acquired an intention exclusive
-    global lock this call is only enforcing asserts.
-  */
-  DBUG_ASSERT(global_lock.is_lock_type_compatible(MDL_EXCLUSIVE, TRUE));
+  old_msg= MDL_ENTER_COND(thd, mysys_var, &m_ctx->m_ctx_wakeup_cond,
+                          &m_lock->m_mutex);
 
@@ -1092,2 +1662,5 @@ MDL_ticket::upgrade_shared_lock_to_exclusive()
 
+    MDL_ticket *conflicting_ticket;
+    MDL_lock::Ticket_iterator it(m_lock->granted);
+
     /*
@@ -1115,8 +1688,3 @@ MDL_ticket::upgrade_shared_lock_to_exclusive()
       CREATE/DROP TRIGGER, it's used there just for convenience.
-    */
-    bool signalled= FALSE;
-    MDL_ticket *conflicting_ticket;
-    MDL_lock::Ticket_iterator it(m_lock->granted);
 
-    /*
       A temporary work-around to avoid deadlocks/livelocks in
@@ -1147,3 +1715,3 @@ MDL_ticket::upgrade_shared_lock_to_exclusive()
       if (conflicting_ticket->m_ctx != m_ctx)
-        signalled|= notify_shared_lock(thd, conflicting_ticket);
+        notify_shared_lock(thd, conflicting_ticket);
     }
@@ -1153,25 +1721,29 @@ MDL_ticket::upgrade_shared_lock_to_exclusive()
 
-    if (signalled)
-      pthread_cond_wait(&COND_mdl, &LOCK_mdl);
-    else
+    /*
+      Another thread might have obtained a shared MDL lock on some table
+      but has not yet opened it and/or tried to obtain data lock on it.
+      Also invocation of acquire_exclusive_lock() method and consequently
+      first call to notify_shared_lock() might have happened right after
+      thread holding shared metadata lock in wait_for_locks() method
+      checked that there are no pending conflicting locks but before
+      it has started waiting.
+      In both these cases we need to sleep until these threads will start
+      waiting and try to abort them once again.
+    */
+    struct timespec abstime;
+    set_timespec(abstime, 1);
+    pthread_cond_timedwait(&m_ctx->m_ctx_wakeup_cond, &m_lock->m_mutex,
+                           &abstime);
+
+    if (mysys_var->abort)
     {
+      m_lock->waiting_exclusive.remove(pending_ticket);
       /*
-        Another thread obtained a shared MDL lock on some table but
-        has not yet opened it and/or tried to obtain data lock on
-        it. In this case we need to wait until this happens and try
-        to abort this thread once again.
+        If there are no other pending requests for exclusive locks
+        we need to wake up threads waiting for a chance to acquire
+        shared lock.
       */
-      struct timespec abstime;
-      set_timespec(abstime, 1);
-      DBUG_PRINT("info", ("Failed to wake-up from table-level lock ... sleeping"));
-      pthread_cond_timedwait(&COND_mdl, &LOCK_mdl, &abstime);
-    }
-    if (mysys_var->abort)
-    {
-      /* Remove and destroy the auxiliary pending ticket. */
-      m_lock->waiting.remove(pending_ticket);
+      m_lock->wake_up_waiters();
+      MDL_EXIT_COND(thd, mysys_var, &m_lock->m_mutex, old_msg);
       MDL_ticket::destroy(pending_ticket);
-      /* Pending requests for shared locks can be satisfied now. */
-      pthread_cond_broadcast(&COND_mdl);
-      MDL_EXIT_COND(thd, mysys_var, old_msg);
       DBUG_RETURN(TRUE);
@@ -1180,3 +1752,2 @@ MDL_ticket::upgrade_shared_lock_to_exclusive()
 
-  m_lock->type= MDL_lock::MDL_LOCK_EXCLUSIVE;
   /* Set the new type of lock in the ticket. */
@@ -1185,4 +1756,3 @@ MDL_ticket::upgrade_shared_lock_to_exclusive()
   /* Remove and destroy the auxiliary pending ticket. */
-  m_lock->waiting.remove(pending_ticket);
-  MDL_ticket::destroy(pending_ticket);
+  m_lock->waiting_exclusive.remove(pending_ticket);
 
@@ -1192,4 +1762,6 @@ MDL_ticket::upgrade_shared_lock_to_exclusive()
 
-  /* As a side-effect MDL_EXIT_COND() unlocks LOCK_mdl. */
-  MDL_EXIT_COND(thd, mysys_var, old_msg);
+  MDL_EXIT_COND(thd, mysys_var, &m_lock->m_mutex, old_msg);
+
+  MDL_ticket::destroy(pending_ticket);
+
   DBUG_RETURN(FALSE);
@@ -1224,37 +1796,6 @@ MDL_context::try_acquire_exclusive_lock(MDL_request *mdl_request)
 {
-  MDL_lock *lock;
-  MDL_ticket *ticket;
-  MDL_key *key= &mdl_request->key;
-
-  DBUG_ASSERT(mdl_request->type == MDL_EXCLUSIVE &&
-              mdl_request->ticket == NULL);
-
-  safe_mutex_assert_not_owner(&LOCK_open);
-
-  mdl_request->ticket= NULL;
-
-  pthread_mutex_lock(&LOCK_mdl);
+  DBUG_ASSERT(mdl_request->type == MDL_EXCLUSIVE);
+  DBUG_ASSERT(is_global_lock_owner(MDL_INTENTION_EXCLUSIVE));
 
-  if (!(lock= (MDL_lock*) my_hash_search(&mdl_locks,
-                                         key->ptr(), key->length())))
-  {
-    ticket= MDL_ticket::create(this, mdl_request->type);
-    lock= MDL_lock::create(key);
-    if (!ticket || !lock || my_hash_insert(&mdl_locks, (uchar*)lock))
-    {
-      MDL_ticket::destroy(ticket);
-      MDL_lock::destroy(lock);
-      pthread_mutex_unlock(&LOCK_mdl);
-      return TRUE;
-    }
-    mdl_request->ticket= ticket;
-    lock->type= MDL_lock::MDL_LOCK_EXCLUSIVE;
-    lock->granted.push_front(ticket);
-    m_tickets.push_front(ticket);
-    ticket->m_state= MDL_ACQUIRED;
-    ticket->m_lock= lock;
-    global_lock.active_intention_exclusive++;
-  }
-  pthread_mutex_unlock(&LOCK_mdl);
-  return FALSE;
+  return try_acquire_lock_impl(mdl_request);
 }
@@ -1274,27 +1815,13 @@ bool MDL_context::acquire_global_shared_lock()
 {
-  st_my_thread_var *mysys_var= my_thread_var;
-  const char *old_msg;
+  MDL_request mdl_request;
 
-  safe_mutex_assert_not_owner(&LOCK_open);
-  DBUG_ASSERT(!m_has_global_shared_lock);
+  DBUG_ASSERT(! is_global_lock_owner(MDL_SHARED));
 
-  pthread_mutex_lock(&LOCK_mdl);
+  mdl_request.init(MDL_key::GLOBAL, "", "", MDL_SHARED);
 
-  global_lock.waiting_shared++;
-  old_msg= MDL_ENTER_COND(m_thd, mysys_var);
+  if (acquire_lock_impl(&mdl_request))
+    return TRUE;
 
-  while (!mysys_var->abort && global_lock.active_intention_exclusive)
-    pthread_cond_wait(&COND_mdl, &LOCK_mdl);
+  move_ticket_after_lt_or_ha_sentinel(mdl_request.ticket);
 
-  global_lock.waiting_shared--;
-  if (mysys_var->abort)
-  {
-    /* As a side-effect MDL_EXIT_COND() unlocks LOCK_mdl. */
-    MDL_EXIT_COND(m_thd, mysys_var, old_msg);
-    return TRUE;
-  }
-  global_lock.active_shared++;
-  m_has_global_shared_lock= TRUE;
-  /* As a side-effect MDL_EXIT_COND() unlocks LOCK_mdl. */
-  MDL_EXIT_COND(m_thd, mysys_var, old_msg);
   return FALSE;
@@ -1304,6 +1831,6 @@ bool MDL_context::acquire_global_shared_lock()
 /**
-  Check if there are any pending exclusive locks which conflict
-  with shared locks held by this thread.
-
-  @pre The caller already has acquired LOCK_mdl.
+  Implement a simple deadlock detection heuristic: check if there
+  are any pending exclusive locks which conflict with shared locks
+  held by this thread. In that case waiting can be circular,
+  i.e. lead to a deadlock.
 
@@ -1313,3 +1840,3 @@ bool MDL_context::acquire_global_shared_lock()
 
-bool MDL_context::can_wait_lead_to_deadlock_impl() const
+bool MDL_context::can_wait_lead_to_deadlock() const
 {
@@ -1325,3 +1852,3 @@ bool MDL_context::can_wait_lead_to_deadlock_impl() const
       requests for conflicting types of global lock.
-      In addition MDL_ticket::has_pending_conflicting_lock_impl()
+      In addition MDL_ticket::has_pending_conflicting_lock()
       won't work properly for exclusive type of lock.
@@ -1330,3 +1857,3 @@ bool MDL_context::can_wait_lead_to_deadlock_impl() const
 
-    if (ticket->has_pending_conflicting_lock_impl())
+    if (ticket->has_pending_conflicting_lock())
       return TRUE;
@@ -1338,21 +1865,2 @@ bool MDL_context::can_wait_lead_to_deadlock_impl() const
 /**
-  Implement a simple deadlock detection heuristic: check if there
-  are any pending exclusive locks which conflict with shared locks
-  held by this thread. In that case waiting can be circular,
-  i.e. lead to a deadlock.
-
-  @return TRUE if there are any conflicting locks, FALSE otherwise.
-*/
-
-bool MDL_context::can_wait_lead_to_deadlock() const
-{
-  bool result;
-  pthread_mutex_lock(&LOCK_mdl);
-  result= can_wait_lead_to_deadlock_impl();
-  pthread_mutex_unlock(&LOCK_mdl);
-  return result;
-}
-
-
-/**
   Wait until there will be no locks that conflict with lock requests
@@ -1393,4 +1901,2 @@ MDL_context::wait_for_locks(MDL_request_list *mdl_requests)
     mysql_ha_flush(m_thd);
-    pthread_mutex_lock(&LOCK_mdl);
-    old_msg= MDL_ENTER_COND(m_thd, mysys_var);
 
@@ -1408,5 +1914,4 @@ MDL_context::wait_for_locks(MDL_request_list *mdl_requests)
     */
-    if (can_wait_lead_to_deadlock_impl())
+    if (can_wait_lead_to_deadlock())
     {
-      MDL_EXIT_COND(m_thd, mysys_var, old_msg);
       my_error(ER_LOCK_DEADLOCK, MYF(0));
@@ -1420,4 +1925,3 @@ MDL_context::wait_for_locks(MDL_request_list *mdl_requests)
       DBUG_ASSERT(mdl_request->ticket == NULL);
-      if (!global_lock.is_lock_type_compatible(mdl_request->type, FALSE))
-        break;
+
       /*
@@ -1426,7 +1930,50 @@ MDL_context::wait_for_locks(MDL_request_list *mdl_requests)
       */
-      if (mdl_request->is_shared() &&
-          (lock= (MDL_lock*) my_hash_search(&mdl_locks, key->ptr(),
-                                            key->length())) &&
-          !lock->can_grant_lock(this, mdl_request->type, FALSE))
+      if (mdl_request->is_shared() ||
+          mdl_request->type == MDL_INTENTION_EXCLUSIVE)
+      {
+        /* The below call also implicitly locks MDL_lock::m_mutex. */
+        if (! (lock= mdl_locks.find(key)))
+          continue;
+
+        if (lock->can_grant_lock(this, mdl_request->type, FALSE))
+        {
+          pthread_mutex_unlock(&lock->m_mutex);
+          continue;
+        }
+
+        MDL_ticket *pending_ticket;
+        if (! (pending_ticket= MDL_ticket::create(this, mdl_request->type)))
+        {
+          pthread_mutex_unlock(&lock->m_mutex);
+          return TRUE;
+        }
+        if (mdl_request->is_shared())
+          lock->waiting_shared.push_front(pending_ticket);
+        else
+          lock->waiting_exclusive.push_front(pending_ticket);
+
+        old_msg= MDL_ENTER_COND(m_thd, mysys_var, &m_ctx_wakeup_cond,
+                                &lock->m_mutex);
+
+        pthread_cond_wait(&m_ctx_wakeup_cond, &lock->m_mutex);
+
+        /*
+          We have to do MDL_EXIT_COND here and then re-acquire the lock
+          as there is a chance that we will destroy MDL_lock object and
+          won't be able to call MDL_EXIT_COND after it.
+        */
+        MDL_EXIT_COND(m_thd, mysys_var, &lock->m_mutex, old_msg);
+
+        pthread_mutex_lock(&lock->m_mutex);
+        if (mdl_request->is_shared())
+          lock->waiting_shared.remove(pending_ticket);
+        else
+          lock->waiting_exclusive.remove(pending_ticket);
+        if (lock->is_empty())
+          mdl_locks.remove(lock);
+        else
+          pthread_mutex_unlock(&lock->m_mutex);
+        MDL_ticket::destroy(pending_ticket);
         break;
+      }
     }
@@ -1434,11 +1981,5 @@ MDL_context::wait_for_locks(MDL_request_list *mdl_requests)
     {
-      /* As a side-effect MDL_EXIT_COND() unlocks LOCK_mdl. */
-      MDL_EXIT_COND(m_thd, mysys_var, old_msg);
+      /* There are no conflicts for any locks! */
       break;
     }
-    m_is_waiting_in_mdl= TRUE;
-    pthread_cond_wait(&COND_mdl, &LOCK_mdl);
-    m_is_waiting_in_mdl= FALSE;
-    /* As a side-effect MDL_EXIT_COND() unlocks LOCK_mdl. */
-    MDL_EXIT_COND(m_thd, mysys_var, old_msg);
   }
@@ -1449,10 +1990,11 @@ MDL_context::wait_for_locks(MDL_request_list *mdl_requests)
 /**
-  Auxiliary function which allows to release particular lock
-  ownership of which is represented by a lock ticket object.
+  Release lock.
+
+  @param ticket Ticket for lock to be released.
 */
 
-void MDL_context::release_ticket(MDL_ticket *ticket)
+void MDL_context::release_lock(MDL_ticket *ticket)
 {
   MDL_lock *lock= ticket->m_lock;
-  DBUG_ENTER("release_ticket");
+  DBUG_ENTER("MDL_context::release_lock");
   DBUG_PRINT("enter", ("db=%s name=%s", lock->key.db_name(),
@@ -1460,3 +2002,4 @@ void MDL_context::release_ticket(MDL_ticket *ticket)
 
-  safe_mutex_assert_owner(&LOCK_mdl);
+  DBUG_ASSERT(this == ticket->m_ctx);
+  safe_mutex_assert_not_owner(&LOCK_open);
 
@@ -1465,34 +2008,17 @@ void MDL_context::release_ticket(MDL_ticket *ticket)
 
-  m_tickets.remove(ticket);
-
-  switch (ticket->m_type)
-  {
-    case MDL_SHARED_UPGRADABLE:
-      global_lock.active_intention_exclusive--;
-      /* Fallthrough. */
-    case MDL_SHARED:
-    case MDL_SHARED_HIGH_PRIO:
-      lock->granted.remove(ticket);
-      break;
-    case MDL_EXCLUSIVE:
-      lock->type= MDL_lock::MDL_LOCK_SHARED;
-      lock->granted.remove(ticket);
-      global_lock.active_intention_exclusive--;
-      break;
-    default:
-      DBUG_ASSERT(0);
-  }
+  pthread_mutex_lock(&lock->m_mutex);
 
-  MDL_ticket::destroy(ticket);
+  lock->granted.remove(ticket);
 
   if (lock->is_empty())
+    mdl_locks.remove(lock);
+  else
   {
-    my_hash_delete(&mdl_locks, (uchar *)lock);
-    DBUG_PRINT("info", ("releasing cached_object cached_object=%p",
-                        lock->cached_object));
-    if (lock->cached_object)
-      (*lock->cached_object_release_hook)(lock->cached_object);
-    MDL_lock::destroy(lock);
+    lock->wake_up_waiters();
+    pthread_mutex_unlock(&lock->m_mutex);
   }
 
+  m_tickets.remove(ticket);
+  MDL_ticket::destroy(ticket);
+
   DBUG_VOID_RETURN;
@@ -1524,4 +2050,2 @@ void MDL_context::release_locks_stored_before(MDL_ticket *sentinel)
 
-  safe_mutex_assert_not_owner(&LOCK_open);
-
   if (m_tickets.is_empty())
@@ -1529,3 +2053,2 @@ void MDL_context::release_locks_stored_before(MDL_ticket *sentinel)
 
-  pthread_mutex_lock(&LOCK_mdl);
   while ((ticket= it++) && ticket != sentinel)
@@ -1533,7 +2056,10 @@ void MDL_context::release_locks_stored_before(MDL_ticket *sentinel)
     DBUG_PRINT("info", ("found lock to release ticket=%p", ticket));
-    release_ticket(ticket);
+    release_lock(ticket);
   }
-  /* Inefficient but will do for a while */
-  pthread_cond_broadcast(&COND_mdl);
-  pthread_mutex_unlock(&LOCK_mdl);
+  /*
+    If all locks were released, then the sentinel was not present
+    in the list. It must never happen because the sentinel was
+    bogus, i.e. pointed to a ticket that no longer exists.
+  */
+  DBUG_ASSERT(! m_tickets.is_empty() || sentinel == NULL);
 
@@ -1544,20 +2070,2 @@ void MDL_context::release_locks_stored_before(MDL_ticket *sentinel)
 /**
-  Release a lock.
-
-  @param ticket    Lock to be released
-*/
-
-void MDL_context::release_lock(MDL_ticket *ticket)
-{
-  DBUG_ASSERT(this == ticket->m_ctx);
-  safe_mutex_assert_not_owner(&LOCK_open);
-
-  pthread_mutex_lock(&LOCK_mdl);
-  release_ticket(ticket);
-  pthread_cond_broadcast(&COND_mdl);
-  pthread_mutex_unlock(&LOCK_mdl);
-}
-
-
-/**
   Release all locks in the context which correspond to the same name/
@@ -1571,3 +2079,3 @@ void MDL_context::release_all_locks_for_name(MDL_ticket *name)
 {
-  /* Use MDL_ticket::lock to identify other locks for the same object. */
+  /* Use MDL_ticket::m_lock to identify other locks for the same object. */
   MDL_lock *lock= name->m_lock;
@@ -1602,7 +2110,14 @@ void MDL_ticket::downgrade_exclusive_lock()
 
-  pthread_mutex_lock(&LOCK_mdl);
-  m_lock->type= MDL_lock::MDL_LOCK_SHARED;
+  pthread_mutex_lock(&m_lock->m_mutex);
   m_type= MDL_SHARED_UPGRADABLE;
-  pthread_cond_broadcast(&COND_mdl);
-  pthread_mutex_unlock(&LOCK_mdl);
+
+  if (! m_lock->waiting_shared.is_empty())
+  {
+    MDL_lock::Ticket_iterator it(m_lock->waiting_shared);
+    MDL_ticket *ticket;
+    while ((ticket= it++))
+      ticket->get_ctx()->awake();
+  }
+
+  pthread_mutex_unlock(&m_lock->m_mutex);
 }
@@ -1616,10 +2131,18 @@ void MDL_context::release_global_shared_lock()
 {
+  MDL_request mdl_request;
+  MDL_ticket *ticket;
+  bool not_used;
+
+  mdl_request.init(MDL_key::GLOBAL, "", "", MDL_SHARED);
+
   safe_mutex_assert_not_owner(&LOCK_open);
-  DBUG_ASSERT(m_has_global_shared_lock);
 
-  pthread_mutex_lock(&LOCK_mdl);
-  global_lock.active_shared--;
-  m_has_global_shared_lock= FALSE;
-  pthread_cond_broadcast(&COND_mdl);
-  pthread_mutex_unlock(&LOCK_mdl);
+  /*
+    TODO/QQ/FIXME: In theory we always should be able to find
+                   ticket here. But in practice this is not
+                   always TRUE.
+  */
+
+  if ((ticket= find_ticket(&mdl_request, &not_used)))
+    release_lock(ticket);
 }
@@ -1689,3 +2212,2 @@ MDL_context::is_lock_owner(MDL_key::enum_mdl_namespace mdl_namespace,
   @pre The ticket must match an acquired lock.
-  @pre The caller already has acquired LOCK_mdl.
 
@@ -1694,31 +2216,8 @@ MDL_context::is_lock_owner(MDL_key::enum_mdl_namespace mdl_namespace,
 
-bool MDL_ticket::has_pending_conflicting_lock_impl() const
-{
-  DBUG_ASSERT(is_shared());
-  safe_mutex_assert_owner(&LOCK_mdl);
-
-  return !m_lock->waiting.is_empty();
-}
-
-
-/**
-  Check if we have any pending exclusive locks which conflict with
-  existing shared lock.
-
-  @pre The ticket must match an acquired lock.
-
-  @return TRUE if there is a pending conflicting lock request,
-          FALSE otherwise.
-*/
-
 bool MDL_ticket::has_pending_conflicting_lock() const
 {
-  bool result;
-
   safe_mutex_assert_not_owner(&LOCK_open);
+  DBUG_ASSERT(is_shared());
 
-  pthread_mutex_lock(&LOCK_mdl);
-  result= has_pending_conflicting_lock_impl();
-  pthread_mutex_unlock(&LOCK_mdl);
-  return result;
+  return m_lock->has_pending_exclusive_lock();
 }
diff --git a/sql/sp.cc b/sql/sp.cc
index 1375d44..4cbb0f2 100644
--- a/sql/sp.cc
+++ b/sql/sp.cc
@@ -262,3 +262,3 @@ Stored_routine_creation_ctx::load_from_db(THD *thd,
 
-TABLE *open_proc_table_for_read(THD *thd, Open_tables_state *backup)
+TABLE *open_proc_table_for_read(THD *thd, Open_tables_backup *backup)
 {
@@ -384,3 +384,3 @@ db_find_routine(THD *thd, int type, sp_name *name, sp_head **sphp)
   ulong sql_mode, saved_mode= thd->variables.sql_mode;
-  Open_tables_state open_tables_state_backup;
+  Open_tables_backup open_tables_state_backup;
   Stored_program_creation_ctx *creation_ctx;
@@ -1434,3 +1434,3 @@ sp_routine_exists_in_table(THD *thd, int type, sp_name *name)
   int ret;
-  Open_tables_state open_tables_state_backup;
+  Open_tables_backup open_tables_state_backup;
 
diff --git a/sql/sql_base.cc b/sql/sql_base.cc
index 8d3ef37..2f89137 100644
--- a/sql/sql_base.cc
+++ b/sql/sql_base.cc
@@ -1521,21 +1521,19 @@ void close_thread_tables(THD *thd)
 
-  if (thd->state_flags & Open_tables_state::BACKUPS_AVAIL)
-  {
-    /* We can't have an open HANDLER in the backup open tables state. */
-    DBUG_ASSERT(thd->mdl_context.lt_or_ha_sentinel() == NULL);
-    /*
-      Due to the above assert, this is guaranteed to release *all* locks
-      in the context.
-    */
-    thd->mdl_context.release_transactional_locks();
-  }
-  else if (! thd->in_multi_stmt_transaction())
+  /*
+    - If inside a multi-statement transaction,
+    defer the release of metadata locks until the current
+    transaction is either committed or rolled back. This prevents
+    other statements from modifying the table for the entire
+    duration of this transaction.  This provides commit ordering
+    and guarantees serializability across multiple transactions.
+    - If closing a system table, defer the release of metadata locks
+    to the caller. We have no sentinel in MDL subsystem to guard
+    transactional locks from system tables locks, so don't know
+    which locks are which here.
+    - If in autocommit mode, or outside a transactional context,
+    automatically release metadata locks of the current statement.
+  */
+  if (! thd->in_multi_stmt_transaction() &&
+      ! (thd->state_flags & Open_tables_state::BACKUPS_AVAIL))
   {
-    /*
-      Defer the release of metadata locks until the current transaction
-      is either committed or rolled back. This prevents other statements
-      from modifying the table for the entire duration of this transaction.
-      This provides commitment ordering for guaranteeing serializability
-      across multiple transactions.
-    */
     thd->mdl_context.release_transactional_locks();
@@ -2338,6 +2336,5 @@ open_table_get_mdl_lock(THD *thd, TABLE_LIST *table_list,
 {
-  ot_ctx->add_request(mdl_request);
-
   if (table_list->lock_strategy)
   {
+    MDL_request *global_request;
     /*
@@ -2351,6 +2348,20 @@ open_table_get_mdl_lock(THD *thd, TABLE_LIST *table_list,
     */
+
     mdl_request->set_type(MDL_EXCLUSIVE);
     DBUG_ASSERT(! thd->mdl_context.has_locks() ||
-                thd->handler_tables_hash.records);
+                thd->handler_tables_hash.records ||
+                thd->global_read_lock);
+
+    if (!(global_request= ot_ctx->get_global_mdl_request(thd)))
+      return 1;
 
+    if (! global_request->ticket)
+    {
+      ot_ctx->add_request(global_request);
+      if (thd->mdl_context.acquire_global_intention_exclusive_lock(
+                             global_request))
+      return 1;
+    }
+
+    ot_ctx->add_request(mdl_request);
     if (thd->mdl_context.acquire_exclusive_lock(mdl_request))
@@ -2373,4 +2384,25 @@ open_table_get_mdl_lock(THD *thd, TABLE_LIST *table_list,
 
+    if (mdl_request->type == MDL_SHARED_UPGRADABLE)
+    {
+      MDL_request *global_request;
+
+      if (!(global_request= ot_ctx->get_global_mdl_request(thd)))
+        return 1;
+      if (! global_request->ticket)
+      {
+        ot_ctx->add_request(global_request);
+        if (thd->mdl_context.try_acquire_global_intention_exclusive_lock(
+                               global_request))
+          return 1;
+        if (! global_request->ticket)
+          goto failure;
+      }
+    }
+
+    ot_ctx->add_request(mdl_request);
+
     if (thd->mdl_context.try_acquire_shared_lock(mdl_request))
       return 1;
+
+failure:
     if (mdl_request->ticket == NULL)
@@ -2921,4 +2953,2 @@ err_unlock2:
   pthread_mutex_unlock(&LOCK_open);
-  if (! (flags & MYSQL_OPEN_HAS_MDL_LOCK))
-    thd->mdl_context.release_lock(mdl_ticket);
 
@@ -3715,3 +3745,4 @@ Open_table_context::Open_table_context(THD *thd)
                 thd->mdl_context.lt_or_ha_sentinel()) &&
-               thd->mdl_context.has_locks())
+               thd->mdl_context.has_locks()),
+   m_global_mdl_request(NULL)
 {}
@@ -3720,2 +3751,24 @@ Open_table_context::Open_table_context(THD *thd)
 /**
+  Get MDL_request object for global intention exclusive lock which
+  is acquired during opening tables for statements which take
+  upgradable shared metadata locks.
+*/
+
+MDL_request *Open_table_context::get_global_mdl_request(THD *thd)
+{
+  if (! m_global_mdl_request)
+  {
+    char *buff;
+    if ((buff= (char*)thd->alloc(sizeof(MDL_request))))
+    {
+      m_global_mdl_request= new (buff) MDL_request();
+      m_global_mdl_request->init(MDL_key::GLOBAL, "", "",
+                                 MDL_INTENTION_EXCLUSIVE);
+    }
+  }
+  return m_global_mdl_request;
+}
+
+
+/**
   Check if we can back-off and set back off action if we can.
@@ -3779,2 +3832,7 @@ recover_from_failed_open(THD *thd, MDL_request *mdl_request,
   bool result= FALSE;
+  /*
+    Remove reference to released ticket from MDL_request.
+  */
+  if (m_global_mdl_request)
+    m_global_mdl_request->ticket= NULL;
   /* Execute the action. */
@@ -3789,7 +3847,22 @@ recover_from_failed_open(THD *thd, MDL_request *mdl_request,
       {
+        MDL_request mdl_global_request;
         MDL_request mdl_xlock_request(mdl_request);
+
+        mdl_global_request.init(MDL_key::GLOBAL, "", "",
+                                MDL_INTENTION_EXCLUSIVE);
         mdl_xlock_request.set_type(MDL_EXCLUSIVE);
+
+
+        if ((result= thd->mdl_context.acquire_global_intention_exclusive_lock(
+                                        &mdl_global_request)))
+          break;
+
         if ((result=
              thd->mdl_context.acquire_exclusive_lock(&mdl_xlock_request)))
+        {
+          /*
+            We rely on close_thread_tables() to release global lock eventually.
+          */
           break;
+        }
 
@@ -3807,3 +3880,3 @@ recover_from_failed_open(THD *thd, MDL_request *mdl_request,
         thd->clear_error();                 // Clear error message
-        thd->mdl_context.release_lock(mdl_xlock_request.ticket);
+        thd->mdl_context.release_transactional_locks();
         break;
@@ -3812,7 +3885,21 @@ recover_from_failed_open(THD *thd, MDL_request *mdl_request,
       {
+        MDL_request mdl_global_request;
         MDL_request mdl_xlock_request(mdl_request);
+
+        mdl_global_request.init(MDL_key::GLOBAL, "", "",
+                                MDL_INTENTION_EXCLUSIVE);
         mdl_xlock_request.set_type(MDL_EXCLUSIVE);
+
+        if ((result= thd->mdl_context.acquire_global_intention_exclusive_lock(
+                                        &mdl_global_request)))
+          break;
+
         if ((result=
              thd->mdl_context.acquire_exclusive_lock(&mdl_xlock_request)))
+        {
+          /*
+            We rely on close_thread_tables() to release global lock eventually.
+          */
           break;
+        }
 
@@ -3826,3 +3913,3 @@ recover_from_failed_open(THD *thd, MDL_request *mdl_request,
         result= auto_repair_table(thd, table);
-        thd->mdl_context.release_lock(mdl_xlock_request.ticket);
+        thd->mdl_context.release_transactional_locks();
         break;
@@ -3923,2 +4010,9 @@ open_and_process_routine(THD *thd, Query_tables_list *prelocking_ctx,
         ot_ctx->add_request(&rt->mdl_request);
+
+        /*
+          Since we acquire only shared lock on routines we don't
+          need to care about global intention exclusive locks.
+        */
+        DBUG_ASSERT(rt->mdl_request.type == MDL_SHARED);
+
         if (thd->mdl_context.try_acquire_shared_lock(&rt->mdl_request))
@@ -8786,3 +8880,3 @@ bool
 open_system_tables_for_read(THD *thd, TABLE_LIST *table_list,
-                            Open_tables_state *backup)
+                            Open_tables_backup *backup)
 {
@@ -8832,3 +8926,3 @@ error:
       thd     Thread context
-      backup  Pointer to Open_tables_state instance which holds
+      backup  Pointer to Open_tables_backup instance which holds
               information about tables which were open before we
@@ -8838,3 +8932,3 @@ error:
 void
-close_system_tables(THD *thd, Open_tables_state *backup)
+close_system_tables(THD *thd, Open_tables_backup *backup)
 {
@@ -8889,3 +8983,3 @@ TABLE *
 open_performance_schema_table(THD *thd, TABLE_LIST *one_table,
-                              Open_tables_state *backup)
+                              Open_tables_backup *backup)
 {
@@ -8938,47 +9032,5 @@ open_performance_schema_table(THD *thd, TABLE_LIST *one_table,
 */
-void close_performance_schema_table(THD *thd, Open_tables_state *backup)
+void close_performance_schema_table(THD *thd, Open_tables_backup *backup)
 {
-  bool found_old_table;
-
-  /*
-    If open_performance_schema_table() fails,
-    this function should not be called.
-  */
-  DBUG_ASSERT(thd->lock != NULL);
-
-  /*
-    Note:
-    We do not create explicitly a separate transaction for the
-    performance table I/O, but borrow the current transaction.
-    lock + unlock will autocommit the change done in the
-    performance schema table: this is the expected result.
-    The current transaction should not be affected by this code.
-    TODO: Note that if a transactional engine is used for log tables,
-    this code will need to be revised, as a separate transaction
-    might be needed.
-  */
-  mysql_unlock_tables(thd, thd->lock);
-  thd->lock= 0;
-
-  pthread_mutex_lock(&LOCK_open);
-
-  found_old_table= false;
-  /*
-    Note that we need to hold LOCK_open while changing the
-    open_tables list. Another thread may work on it.
-    (See: notify_thread_having_shared_lock())
-  */
-  while (thd->open_tables)
-    found_old_table|= close_thread_table(thd, &thd->open_tables);
-
-  if (found_old_table)
-    broadcast_refresh();
-
-  pthread_mutex_unlock(&LOCK_open);
-
-  /* We can't have an open HANDLER in the backup context. */
-  DBUG_ASSERT(thd->mdl_context.lt_or_ha_sentinel() == NULL);
-  thd->mdl_context.release_transactional_locks();
-
-  thd->restore_backup_open_tables_state(backup);
+  close_system_tables(thd, backup);
 }
diff --git a/sql/sql_class.cc b/sql/sql_class.cc
index 95c985b..62de06d 100644
--- a/sql/sql_class.cc
+++ b/sql/sql_class.cc
@@ -473,2 +473,3 @@ THD::THD()
 
+  mdl_context.init(this);
   /*
@@ -1009,3 +1010,4 @@ void THD::cleanup(void)
   /* All HANDLERs must have been closed by now. */
-  DBUG_ASSERT(mdl_context.lt_or_ha_sentinel() == NULL);
+  DBUG_ASSERT(mdl_context.lt_or_ha_sentinel() == NULL ||
+              global_read_lock);
   /*
@@ -3026,3 +3028,3 @@ bool Security_context::user_matches(Security_context *them)
 
-void THD::reset_n_backup_open_tables_state(Open_tables_state *backup)
+void THD::reset_n_backup_open_tables_state(Open_tables_backup *backup)
 {
@@ -3030,2 +3032,3 @@ void THD::reset_n_backup_open_tables_state(Open_tables_state *backup)
   backup->set_open_tables_state(this);
+  backup->mdl_system_tables_svp= mdl_context.mdl_savepoint();
   reset_open_tables_state(this);
@@ -3036,5 +3039,6 @@ void THD::reset_n_backup_open_tables_state(Open_tables_state *backup)
 
-void THD::restore_backup_open_tables_state(Open_tables_state *backup)
+void THD::restore_backup_open_tables_state(Open_tables_backup *backup)
 {
   DBUG_ENTER("restore_backup_open_tables_state");
+  mdl_context.rollback_to_savepoint(backup->mdl_system_tables_svp);
   /*
@@ -3048,3 +3052,2 @@ void THD::restore_backup_open_tables_state(Open_tables_state *backup)
               m_reprepare_observer == NULL);
-  mdl_context.destroy();
 
diff --git a/sql/sql_delete.cc b/sql/sql_delete.cc
index 26478b3..228c001 100644
--- a/sql/sql_delete.cc
+++ b/sql/sql_delete.cc
@@ -1102,3 +1102,3 @@ bool mysql_truncate(THD *thd, TABLE_LIST *table_list, bool dont_send_ok)
   uint path_length;
-  MDL_request mdl_request;
+  MDL_request mdl_global_request, mdl_request;
   /*
@@ -1209,6 +1209,17 @@ bool mysql_truncate(THD *thd, TABLE_LIST *table_list, bool dont_send_ok)
       */
+
+      mdl_global_request.init(MDL_key::GLOBAL, "", "", MDL_INTENTION_EXCLUSIVE);
       mdl_request.init(MDL_key::TABLE, table_list->db, table_list->table_name,
                        MDL_EXCLUSIVE);
+      if (thd->mdl_context.acquire_global_intention_exclusive_lock(
+                             &mdl_global_request))
+        DBUG_RETURN(TRUE);
       if (thd->mdl_context.acquire_exclusive_lock(&mdl_request))
+      {
+        /*
+          We rely on that close_thread_tables() to release global lock
+          in this case.
+        */
         DBUG_RETURN(TRUE);
+      }
       has_mdl_lock= TRUE;
@@ -1252,3 +1263,3 @@ end:
     if (has_mdl_lock)
-      thd->mdl_context.release_lock(mdl_request.ticket);
+      thd->mdl_context.release_transactional_locks();
     if (mdl_ticket)
diff --git a/sql/sql_help.cc b/sql/sql_help.cc
index af67db4..e9b15e0 100644
--- a/sql/sql_help.cc
+++ b/sql/sql_help.cc
@@ -657,3 +657,8 @@ bool mysqld_help(THD *thd, const char *mask)
 
-  Open_tables_state open_tables_state_backup;
+  /*
+    HELP must be available under LOCK TABLES. 
+    Reset and backup the current open tables state to
+    make it possible.
+  */
+  Open_tables_backup open_tables_state_backup;
   if (open_system_tables_for_read(thd, tables, &open_tables_state_backup))
diff --git a/sql/sql_parse.cc b/sql/sql_parse.cc
index 486cb9a..3976744 100644
--- a/sql/sql_parse.cc
+++ b/sql/sql_parse.cc
@@ -6504,3 +6504,4 @@ bool reload_acl_and_cache(THD *thd, ulong options, TABLE_LIST *tables,
               !thd->mdl_context.has_locks() ||
-              thd->handler_tables_hash.records);
+              thd->handler_tables_hash.records ||
+              thd->global_read_lock);
 
diff --git a/sql/sql_show.cc b/sql/sql_show.cc
index e9d1426..278e0c1 100644
--- a/sql/sql_show.cc
+++ b/sql/sql_show.cc
@@ -2873,3 +2873,3 @@ make_table_name_list(THD *thd, List<LEX_STRING> *table_names, LEX *lex,
                                            conflicting lock is present.
-  @param[in]      open_tables_state_backup pointer to Open_tables_state object
+  @param[in]      open_tables_state_backup pointer to Open_tables_backup object
                                            which is used to save|restore original
@@ -2887,3 +2887,3 @@ fill_schema_show_cols_or_idxs(THD *thd, TABLE_LIST *tables,
                               bool can_deadlock,
-                              Open_tables_state *open_tables_state_backup)
+                              Open_tables_backup *open_tables_state_backup)
 {
@@ -2943,3 +2943,4 @@ fill_schema_show_cols_or_idxs(THD *thd, TABLE_LIST *tables,
    thd->temporary_tables= 0;
-   close_tables_for_reopen(thd, &show_table_list, NULL);
+   close_tables_for_reopen(thd, &show_table_list,
+                           open_tables_state_backup->mdl_system_tables_svp);
    DBUG_RETURN(error);
@@ -3238,4 +3239,8 @@ end_unlock:
   pthread_mutex_unlock(&LOCK_open);
+  /*
+    Don't release the MDL lock, it can be part of a transaction.
+    If it is not, it will be released by the call to
+    MDL_context::rollback_to_savepoint() in the caller.
+  */
 
-  thd->mdl_context.release_lock(table_list.mdl_request.ticket);
   thd->clear_error();
@@ -3283,3 +3288,3 @@ int get_all_tables(THD *thd, TABLE_LIST *tables, COND *cond)
   int error= 1;
-  Open_tables_state open_tables_state_backup;
+  Open_tables_backup open_tables_state_backup;
   bool save_view_prepare_mode= lex->view_prepare_mode;
@@ -3502,3 +3507,4 @@ int get_all_tables(THD *thd, TABLE_LIST *tables, COND *cond)
                                                &tmp_lex_string);
-              close_tables_for_reopen(thd, &show_table_list, NULL);
+              close_tables_for_reopen(thd, &show_table_list,
+                                      open_tables_state_backup.mdl_system_tables_svp);
             }
@@ -4304,3 +4310,3 @@ int fill_schema_proc(THD *thd, TABLE_LIST *tables, COND *cond)
   char definer[USER_HOST_BUFF_SIZE];
-  Open_tables_state open_tables_state_backup;
+  Open_tables_backup open_tables_state_backup;
   DBUG_ENTER("fill_schema_proc");
diff --git a/sql/sql_table.cc b/sql/sql_table.cc
index 30d6eff..e8c2af4 100644
--- a/sql/sql_table.cc
+++ b/sql/sql_table.cc
@@ -2209,18 +2209,22 @@ err:
     */
-    if (thd->locked_tables_mode &&
-        thd->lock && thd->lock->table_count == 0 && non_temp_tables_count > 0)
-    {
-      thd->locked_tables_list.unlock_locked_tables(thd);
-      goto end;
-    }
-    for (table= tables; table; table= table->next_local)
+    if (! thd->locked_tables_mode)
+      unlock_table_names(thd);
+    else
     {
-      if (table->mdl_request.ticket)
+      if (thd->lock && thd->lock->table_count == 0 && non_temp_tables_count > 0)
       {
-        /*
-          Under LOCK TABLES we may have several instances of table open
-          and locked and therefore have to remove several metadata lock
-          requests associated with them.
-        */
-        thd->mdl_context.release_all_locks_for_name(table->mdl_request.ticket);
+        thd->locked_tables_list.unlock_locked_tables(thd);
+        goto end;
+      }
+      for (table= tables; table; table= table->next_local)
+      {
+        if (table->mdl_request.ticket)
+        {
+          /*
+            Under LOCK TABLES we may have several instances of table open
+            and locked and therefore have to remove several metadata lock
+            requests associated with them.
+          */
+          thd->mdl_context.release_all_locks_for_name(table->mdl_request.ticket);
+        }
       }
@@ -4352,2 +4356,10 @@ static int prepare_for_repair(THD *thd, TABLE_LIST *table_list,
     /*
+      If the table didn't exist, we have a shared metadata lock
+      on it that is left from mysql_admin_table()'s attempt to 
+      open it. Release the shared metadata lock before trying to
+      acquire the exclusive lock to satisfy MDL asserts and avoid
+      deadlocks.
+    */
+    thd->mdl_context.release_transactional_locks();
+    /*
       Attempt to do full-blown table open in mysql_admin_table() has failed.
@@ -4362,2 +4374,10 @@ static int prepare_for_repair(THD *thd, TABLE_LIST *table_list,
                                  MDL_EXCLUSIVE);
+
+    MDL_request mdl_global_request;
+    mdl_global_request.init(MDL_key::GLOBAL, "", "", MDL_INTENTION_EXCLUSIVE);
+
+    if (thd->mdl_context.acquire_global_intention_exclusive_lock(
+               &mdl_global_request))
+      DBUG_RETURN(0);
+
     if (thd->mdl_context.acquire_exclusive_lock(&table_list->mdl_request))
@@ -4493,3 +4513,3 @@ end:
   if (error && has_mdl_lock)
-    thd->mdl_context.release_lock(table_list->mdl_request.ticket);
+    thd->mdl_context.release_transactional_locks();
 
@@ -6546,2 +6566,9 @@ view_err:
                                 MDL_EXCLUSIVE);
+        /*
+          Global intention exclusive lock must have been already acquired when
+          table to be altered was open, so there is no need to do it here.
+        */
+        DBUG_ASSERT(thd->
+                    mdl_context.is_global_lock_owner(MDL_INTENTION_EXCLUSIVE));
+
         if (thd->mdl_context.try_acquire_exclusive_lock(&target_mdl_request))
diff --git a/sql/tztime.cc b/sql/tztime.cc
index 2ec6410..aa97807 100644
--- a/sql/tztime.cc
+++ b/sql/tztime.cc
@@ -1565,3 +1565,2 @@ my_tz_init(THD *org_thd, const char *default_tzname, my_bool bootstrap)
   TABLE_LIST tz_tables[1+MY_TZ_TABLES_COUNT];
-  Open_tables_state open_tables_state_backup;
   TABLE *table;
@@ -1644,3 +1643,4 @@ my_tz_init(THD *org_thd, const char *default_tzname, my_bool bootstrap)
   */
-  if (open_system_tables_for_read(thd, tz_tables, &open_tables_state_backup))
+  if (open_and_lock_tables_derived(thd, tz_tables, FALSE,
+                                   MYSQL_LOCK_IGNORE_FLUSH))
   {
@@ -1653,2 +1653,5 @@ my_tz_init(THD *org_thd, const char *default_tzname, my_bool bootstrap)
 
+  for (TABLE_LIST *tl= tz_tables; tl; tl= tl->next_global)
+    tl->table->use_all_columns();
+
   /*
@@ -1741,3 +1744,4 @@ end_with_close:
     thd->version--; /* Force close to free memory */
-    close_system_tables(thd, &open_tables_state_backup);
+    close_thread_tables(thd);
+    thd->mdl_context.release_transactional_locks();
   }
@@ -2295,3 +2299,3 @@ my_tz_find(THD *thd, const String *name)
       TABLE_LIST tz_tables[MY_TZ_TABLES_COUNT];
-      Open_tables_state open_tables_state_backup;
+      Open_tables_backup open_tables_state_backup;
 